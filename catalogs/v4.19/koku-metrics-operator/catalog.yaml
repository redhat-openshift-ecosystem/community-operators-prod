---
defaultChannel: beta
icon:
  base64data: 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
  mediatype: image/svg+xml
name: koku-metrics-operator
schema: olm.package
---
entries:
- name: koku-metrics-operator.v0.9.0
- name: koku-metrics-operator.v0.9.1
  replaces: koku-metrics-operator.v0.9.0
- name: koku-metrics-operator.v0.9.2
  replaces: koku-metrics-operator.v0.9.1
- name: koku-metrics-operator.v0.9.3
  replaces: koku-metrics-operator.v0.9.2
- name: koku-metrics-operator.v0.9.4
  replaces: koku-metrics-operator.v0.9.3
- name: koku-metrics-operator.v0.9.5
  replaces: koku-metrics-operator.v0.9.4
- name: koku-metrics-operator.v0.9.6
  replaces: koku-metrics-operator.v0.9.5
- name: koku-metrics-operator.v0.9.7
  replaces: koku-metrics-operator.v0.9.6
- name: koku-metrics-operator.v0.9.8
  replaces: koku-metrics-operator.v0.9.7
- name: koku-metrics-operator.v1.1.1
  replaces: koku-metrics-operator.v0.9.8
- name: koku-metrics-operator.v1.1.2
  replaces: koku-metrics-operator.v1.1.1
- name: koku-metrics-operator.v1.1.3
  replaces: koku-metrics-operator.v1.1.2
- name: koku-metrics-operator.v1.1.4
  replaces: koku-metrics-operator.v1.1.3
- name: koku-metrics-operator.v1.1.5
  replaces: koku-metrics-operator.v1.1.4
- name: koku-metrics-operator.v1.1.6
  replaces: koku-metrics-operator.v1.1.5
- name: koku-metrics-operator.v1.1.7
  replaces: koku-metrics-operator.v1.1.6
- name: koku-metrics-operator.v1.1.8
  replaces: koku-metrics-operator.v1.1.7
- name: koku-metrics-operator.v1.1.9
  replaces: koku-metrics-operator.v1.1.8
- name: koku-metrics-operator.v1.2.0
  replaces: koku-metrics-operator.v1.1.9
- name: koku-metrics-operator.v2.0.0
  replaces: koku-metrics-operator.v1.2.0
- name: koku-metrics-operator.v3.0.0
  replaces: koku-metrics-operator.v2.0.0
- name: koku-metrics-operator.v3.0.1
  replaces: koku-metrics-operator.v3.0.0
- name: koku-metrics-operator.v3.1.0
  replaces: koku-metrics-operator.v3.0.1
- name: koku-metrics-operator.v3.2.0
  replaces: koku-metrics-operator.v3.1.0
- name: koku-metrics-operator.v3.2.1
  replaces: koku-metrics-operator.v3.2.0
- name: koku-metrics-operator.v3.3.0
  replaces: koku-metrics-operator.v3.2.1
- name: koku-metrics-operator.v3.3.1
  replaces: koku-metrics-operator.v3.3.0
- name: koku-metrics-operator.v3.3.2
  replaces: koku-metrics-operator.v3.3.1
- name: koku-metrics-operator.v4.0.0
  replaces: koku-metrics-operator.v3.3.2
name: alpha
package: koku-metrics-operator
schema: olm.channel
---
entries:
- name: koku-metrics-operator.v0.9.0
- name: koku-metrics-operator.v0.9.1
  replaces: koku-metrics-operator.v0.9.0
- name: koku-metrics-operator.v0.9.2
  replaces: koku-metrics-operator.v0.9.1
- name: koku-metrics-operator.v0.9.3
  replaces: koku-metrics-operator.v0.9.2
- name: koku-metrics-operator.v0.9.4
  replaces: koku-metrics-operator.v0.9.3
- name: koku-metrics-operator.v0.9.5
  replaces: koku-metrics-operator.v0.9.4
- name: koku-metrics-operator.v0.9.6
  replaces: koku-metrics-operator.v0.9.5
- name: koku-metrics-operator.v0.9.7
  replaces: koku-metrics-operator.v0.9.6
- name: koku-metrics-operator.v0.9.8
  replaces: koku-metrics-operator.v0.9.7
- name: koku-metrics-operator.v1.1.1
  replaces: koku-metrics-operator.v0.9.8
- name: koku-metrics-operator.v1.1.2
  replaces: koku-metrics-operator.v1.1.1
- name: koku-metrics-operator.v1.1.3
  replaces: koku-metrics-operator.v1.1.2
- name: koku-metrics-operator.v1.1.4
  replaces: koku-metrics-operator.v1.1.3
- name: koku-metrics-operator.v1.1.5
  replaces: koku-metrics-operator.v1.1.4
- name: koku-metrics-operator.v1.1.6
  replaces: koku-metrics-operator.v1.1.5
- name: koku-metrics-operator.v1.1.7
  replaces: koku-metrics-operator.v1.1.6
- name: koku-metrics-operator.v1.1.8
  replaces: koku-metrics-operator.v1.1.7
- name: koku-metrics-operator.v1.1.9
  replaces: koku-metrics-operator.v1.1.8
- name: koku-metrics-operator.v1.2.0
  replaces: koku-metrics-operator.v1.1.9
- name: koku-metrics-operator.v2.0.0
  replaces: koku-metrics-operator.v1.2.0
- name: koku-metrics-operator.v3.0.0
  replaces: koku-metrics-operator.v2.0.0
- name: koku-metrics-operator.v3.0.1
  replaces: koku-metrics-operator.v3.0.0
- name: koku-metrics-operator.v3.1.0
  replaces: koku-metrics-operator.v3.0.1
- name: koku-metrics-operator.v3.2.0
  replaces: koku-metrics-operator.v3.1.0
- name: koku-metrics-operator.v3.2.1
  replaces: koku-metrics-operator.v3.2.0
- name: koku-metrics-operator.v3.3.0
  replaces: koku-metrics-operator.v3.2.1
- name: koku-metrics-operator.v3.3.1
  replaces: koku-metrics-operator.v3.3.0
- name: koku-metrics-operator.v3.3.2
  replaces: koku-metrics-operator.v3.3.1
- name: koku-metrics-operator.v4.0.0
  replaces: koku-metrics-operator.v3.3.2
name: beta
package: koku-metrics-operator
schema: olm.channel
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2a01496c44db0d7f9db40da7cbbb3cc3a93047b62f65a8bd4a3228c794495bc9
name: koku-metrics-operator.v0.9.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1alpha1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1alpha1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Basic Install
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator:v0.9.0
      createdAt: "2020-12-14T18:59:19Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.operatorframework.io/builder: operator-sdk-v0.19.2
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Managment
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1alpha1
    description: "# v0.9.0-alpha Koku Metrics Operator (Unsupported)\n## Introduction\nThe
      `koku-metrics-operator` is an OpenShift Operator used to obtain OpenShift usage
      data and upload it to [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management).
      The Operator queries Prometheus to create metric reports, which are then packaged
      and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com).
      For more information, reach out to <cost-mgmt@redhat.com>.\n## Features and
      Capabilities\nThe Koku Metrics Operator (`koku-metrics-operator`) collects the
      metrics required for cost management by:\n* Querying Prometheus to create reports
      specific to cost management.\n* Packaging these reports as a tarball which is
      uploaded to cost management through cloud.redhat.com.\n* The operator is also
      capable of creating a source in cloud.redhat.com. A source is required for cost
      management to process the upload.\n#### Limitations (Potential for metrics data
      loss)\n* Report storage is not backed by a PersitentVolume. If the operator
      is redeployed, a gap may be introduced in the usage metrics.\n* A source **must**
      exist in cloud.redhat.com for an uploaded payload to be processed by cost management.
      The operator sends the payload to the Red Hat Insights Ingress service which
      usually returns successfully, but the operator does not currently confirm with
      cost management that the payload was processed. After Ingress accepts the uploaded
      payload, the payload is removed from the operator and is gone forever. If the
      data within the payload is not processed, a gap will be introduced in the usage
      metrics.\n## Installation\nThe operator must be installed in the `koku-metrics-operator`
      namespace. The namespace can be created through either the UI or CLI:\n####
      Namespace creation:\n##### UI\n1. On the left navigation pane, select `Administration`
      -> `Namespaces` -> `Create Namespace`.\n2. Name the namespace `koku-metrics-operator`.\n3.
      Select `Create`.\n##### CLI\n1. Run the following via the CLI to create and
      use the `koku-metrics-operator` project:\n```\noc new-project koku-metrics-operator\n```\n####
      Operator installation:\nEnsure that the operator is installed into the `koku-metrics-operator`
      namespace.\n\n## Configure the koku-metrics-operator\nThe operator can be configured
      through either the UI or CLI:\n#### Configure through the UI\n##### Configure
      authentication\nThe default authentication for the operator is `token`. No further
      steps are required to configure token authentication. If `basic` is the preferred
      authentication method, a Secret must be created which holds username and password
      credentials:\n1. On the left navigation pane, select `Workloads` -> `Secrets`
      -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`\n2.
      Give the Secret a name and add 2 keys: `username` and `password` (all lowercase).
      The values for these keys correspond to cloud.redhat.com credentials.\n3. Select
      `Create`.\n##### Create the KokuMetricsConfig\nConfigure the koku-metrics-operator
      by creating a `KokuMetricsConfig`.\n1. On the left navigation pane, select `Operators`
      -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` ->
      `Create Instance`.\n2. For `basic` authentication, edit the following values
      in the spec:\n    * Replace `authentication: type:` with `basic`.\n    * Add
      the`secret_name` field under `authentication`, and set it equal to the name
      of the authentication Secret that was created above. The spec should look similar
      to the following:\n\n        ```\n          authentication:\n            secret_name:
      SECRET-NAME\n            type: basic\n        ```\n\n3. To configure the koku-metrics-operator
      to create a cost management source, edit the following values in the `source`
      field:\n    * Replace `INSERT-SOURCE-NAME` with the preferred name of the source
      to be created.\n    * Replace the `create_source` field value with `true`.\n\n
      \   **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with
      the existing name, and leave `create_source` as false. This will allow the operator
      to confirm the source exists.\n4. Select `Create`.\n\n#### Configure through
      the CLI\n##### Configure authentication\nThe default configuration method for
      the operator to create sources and upload to [cloud.redhat.com](https://cloud.redhat.com/)
      is `token`. No further steps are required for configuring `token` authentication.
      If `basic` is the preferred authentication method, a Secret must be created
      which holds username and password credentials:\n1. Copy the following into a
      file called `auth-secret.yaml`:\n\n    ```\n    kind: Secret\n    apiVersion:
      v1\n    metadata:\n      name: authentication-secret\n      namespace: koku-metrics-operator\n
      \   data:\n    username: >-\n      Y2xvdWQucmVkaGF0LmNvbSB1c2VybmFtZQ==\n    password:
      >-\n      Y2xvdWQucmVkaGF0LmNvbSBwYXNzd29yZA==\n    ```\n\n2. Replace the metadata.name
      with the preferred name for the authentication secret.\n3. Replace the `username`
      and `password` values with the base64-encoded username and password credentials
      for logging into cloud.redhat.com.\n4. Deploy the secret to the `koku-metrics-operator`
      namespace:\n    ```\n    $ oc create -f auth-secret.yaml\n    ```\n\n    **Note:**
      The name of the secret should match the `spec:  authentication:  secret_name`
      set in the KokuMetricsConfig that is going to be configured in the next steps.\n\n#####
      Create the KokuMetricsConfig\nConfigure the koku-metrics-operator by creating
      a `KokuMetricsConfig`.\n1. Copy the following `KokuMetricsConfig` resource template
      and save it to a file called `kokumetricsconfig.yaml`:\n\n    ```\n    apiVersion:
      koku-metrics-cfg.openshift.io/v1alpha1\n    kind: KokuMetricsConfig\n    metadata:\n
      \     name: kokumetricscfg-sample\n    spec:\n      authentication:\n        type:
      token\n      packaging:\n        max_size_MB: 100\n      prometheus_config:
      {}\n      source:\n        check_cycle: 1440,\n        create_source: false,\n
      \       name: INSERT-SOURCE-NAME\n      upload:\n        upload_cycle: 360,\n
      \       upload_toggle: true\n    ```\n\n2. To configure the operator to use
      `basic` authentication, edit the following values in the `kokumetricsconfig.yaml`
      file:\n    * Replace `authentication: type:` with `basic`.\n    * Add a field
      called `secret_name` to the authentication field in the spec and set it equal
      to the name of the authentication secret that was created earlier. The authentication
      spec should look similar to the following:\n\n        ```\n          authentication:\n
      \           secret_name: SECRET-NAME\n            type: basic\n        ```\n
      \       \n3. To configure the koku-metrics-operator to create a cost management
      source, edit the following values in the `kokumetricsconfig.yaml` file:\n    *
      Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.\n
      \   * Replace `create_source` field value with `true`.\n\n    **Note:** if the
      source already exists, replace `INSERT-SOURCE-NAME` with the existing name,
      and leave `create_source` as false. This will allow the operator to confirm
      the source exists.\n4. Deploy the `KokuMetricsConfig` resource:\n    ```\n    $
      oc create -f kokumetricsconfig.yaml\n    ```\n\nThe koku-metrics-operator will
      now create, package, and upload OpenShift usage reports to cost management."
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: cost-mgmt@redhat.com
      name: cost-mgmt
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0
  name: ""
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2a01496c44db0d7f9db40da7cbbb3cc3a93047b62f65a8bd4a3228c794495bc9
  name: ""
- image: quay.io/project-koku/koku-metrics-operator:v0.9.0
  name: ""
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:718fb584fd2e80e4a6579ef6d031d979b6dc49c70ec48e7079efe451aec66228
name: koku-metrics-operator.v0.9.1
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1alpha1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.1
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1alpha1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator:v0.9.1
      createdAt: "2021-01-08T15:08:27Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.operatorframework.io/builder: operator-sdk-v0.19.2
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Managment
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1alpha1
    description: |-
      # v0.9.1-alpha Koku Metrics Operator (Unsupported)
      ## Introduction
      The `koku-metrics-operator` is an OpenShift Operator used to obtain OpenShift usage data and upload it to [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management). The Operator queries Prometheus to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to create reports specific to cost management.
      * Packaging these reports as a tarball which is uploaded to cost management through cloud.redhat.com.
      * The operator is also capable of creating a source in cloud.redhat.com. A source is required for cost management to process the upload.
      #### Limitations (Potential for metrics data loss)
      * Report storage is not backed by a PersitentVolume. If the operator is redeployed, a gap may be introduced in the usage metrics.
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.
      ## Installation
      The operator must be installed in the `koku-metrics-operator` namespace. Installing the operator through OperatorHub will create the namespace automatically, or it can be created through either the UI or CLI:
      #### Namespace creation:
      ##### UI
      1. On the left navigation pane, select `Administration` -> `Namespaces` -> `Create Namespace`.
      2. Name the namespace `koku-metrics-operator`.
      3. Select `Create`.
      ##### CLI
      1. Run the following via the CLI to create and use the `koku-metrics-operator` project:
      ```
      oc new-project koku-metrics-operator
      ```
      #### Operator installation:
      Ensure that the operator is installed into the `koku-metrics-operator` namespace.

      ## Configure the koku-metrics-operator
      The operator can be configured through either the UI or CLI:
      #### Configure through the UI
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the`secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. Select `Create`.

      #### Configure through the CLI
      ##### Configure authentication
      The default configuration method for the operator to create sources and upload to [cloud.redhat.com](https://cloud.redhat.com/) is `token`. No further steps are required for configuring `token` authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. Copy the following into a file called `auth-secret.yaml`:

          ```
          kind: Secret
          apiVersion: v1
          metadata:
            name: authentication-secret
            namespace: koku-metrics-operator
          data:
          username: >-
            Y2xvdWQucmVkaGF0LmNvbSB1c2VybmFtZQ==
          password: >-
            Y2xvdWQucmVkaGF0LmNvbSBwYXNzd29yZA==
          ```

      2. Replace the metadata.name with the preferred name for the authentication secret.
      3. Replace the `username` and `password` values with the base64-encoded username and password credentials for logging into cloud.redhat.com.
      4. Deploy the secret to the `koku-metrics-operator` namespace:
          ```
          $ oc create -f auth-secret.yaml
          ```

          **Note:** The name of the secret should match the `spec:  authentication:  secret_name` set in the KokuMetricsConfig that is going to be configured in the next steps.

      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. Copy the following `KokuMetricsConfig` resource template and save it to a file called `kokumetricsconfig.yaml`:

          ```
          apiVersion: koku-metrics-cfg.openshift.io/v1alpha1
          kind: KokuMetricsConfig
          metadata:
            name: kokumetricscfg-sample
          spec:
            authentication:
              type: token
            packaging:
              max_size_MB: 100
            prometheus_config: {}
            source:
              check_cycle: 1440,
              create_source: false,
              name: INSERT-SOURCE-NAME
            upload:
              upload_cycle: 360,
              upload_toggle: true
          ```

      2. To configure the operator to use `basic` authentication, edit the following values in the `kokumetricsconfig.yaml` file:
          * Replace `authentication: type:` with `basic`.
          * Add a field called `secret_name` to the authentication field in the spec and set it equal to the name of the authentication secret that was created earlier. The authentication spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `kokumetricsconfig.yaml` file:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. Deploy the `KokuMetricsConfig` resource:
          ```
          $ oc create -f kokumetricsconfig.yaml
          ```

      The koku-metrics-operator will now create, package, and upload OpenShift usage reports to cost management.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: cost-mgmt@redhat.com
      name: cost-mgmt
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0
  name: ""
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:718fb584fd2e80e4a6579ef6d031d979b6dc49c70ec48e7079efe451aec66228
  name: ""
- image: quay.io/project-koku/koku-metrics-operator:v0.9.1
  name: ""
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:14f38ef621799a71de3ecbbe2d240d5514c737516bc88243dcaff9853fef7a8d
name: koku-metrics-operator.v0.9.2
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1alpha1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.2
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1alpha1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator:v0.9.2
      createdAt: "2021-01-28T14:12:57Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Managment
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1alpha1
    description: |-
      # v0.9.2-alpha Koku Metrics Operator (Unsupported)
      ## Introduction
      The `koku-metrics-operator` is an OpenShift Operator used to collect OpenShift usage data and upload it to [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management). The operator queries Prometheus to create metric reports which are packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com).

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: pvc-spec-definition
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: pvc-spec-definition
                spec:
                  storageClassName: gp2
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
        kind: Pod
        apiVersion: v1
        metadata:
          name: volume-shell
        spec:
          volumes:
          - name: koku-metrics-operator-reports
            persistentVolumeClaim:
              claimName: koku-metrics-operator-data
          containers:
          - name: volume-shell
            image: busybox
            command: ['sleep', '3600']
            volumeMounts:
            - name: koku-metrics-operator-reports
              mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Click `Add source` to open the Sources wizard.
      4. Enter a name for the source and click `Next`.
      5. Select `Red Hat Openshift Container Platform` as the source type and Cost Management as the application. Click `Next`.
      6. Enter the cluster identifier into the cloud.redhat.com Sources wizard, and click `Next`.

          **Note:** The cluster identifier can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      7. In the cloud.redhat.com Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: cost-mgmt@redhat.com
      name: cost-mgmt
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:14f38ef621799a71de3ecbbe2d240d5514c737516bc88243dcaff9853fef7a8d
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:947f0eec61e0d77e9c9d074a12a8b792e2450944755307ef564497c9ad1713f1
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:8341e6189d6390949ee100a1bf5215b682774241c1e76631a92d6a5dedde52e3
name: koku-metrics-operator.v0.9.3
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1alpha1
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.3
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1alpha1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1alpha1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          },
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator:v0.9.3
      createdAt: "2021-02-15T19:56:01Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
          (Deprecated)
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1alpha1
    description: |-
      # v0.9.3-alpha Koku Metrics Operator (Unsupported)
      ## Introduction
      The `koku-metrics-operator` is an OpenShift Operator used to collect OpenShift usage data and upload it to [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management). The operator queries Prometheus to create metric reports which are packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com).

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
        kind: Pod
        apiVersion: v1
        metadata:
          name: volume-shell
          namespace: koku-metrics-operator
        spec:
          volumes:
          - name: koku-metrics-operator-reports
            persistentVolumeClaim:
              claimName: koku-metrics-operator-data
          containers:
          - name: volume-shell
            image: busybox
            command: ['sleep', '3600']
            volumeMounts:
            - name: koku-metrics-operator-reports
              mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Click `Add source` to open the Sources wizard.
      4. Enter a name for the source and click `Next`.
      5. Select `Red Hat Openshift Container Platform` as the source type and Cost Management as the application. Click `Next`.
      6. Enter the cluster identifier into the cloud.redhat.com Sources wizard, and click `Next`.

          **Note:** The cluster identifier can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      7. In the cloud.redhat.com Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: cost-mgmt@redhat.com
      name: cost-mgmt
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:8341e6189d6390949ee100a1bf5215b682774241c1e76631a92d6a5dedde52e3
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:a09b76b020abf2768b67a1680db1228124b0292c7fb957f9b75c749a5d0578b7
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:082ad6124b5fb01cdb3f3e50752751254c8d7850961803dd5ef63ce352b5c502
name: koku-metrics-operator.v0.9.4
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1alpha1
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.4
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator:v0.9.4
      createdAt: "2021-02-16T16:03:12Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # v0.9.4 Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is an OpenShift Operator used to collect OpenShift usage data and upload it to [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management). The operator queries Prometheus to create metric reports which are packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com).

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
        kind: Pod
        apiVersion: v1
        metadata:
          name: volume-shell
          namespace: koku-metrics-operator
        spec:
          volumes:
          - name: koku-metrics-operator-reports
            persistentVolumeClaim:
              claimName: koku-metrics-operator-data
          containers:
          - name: volume-shell
            image: busybox
            command: ['sleep', '3600']
            volumeMounts:
            - name: koku-metrics-operator-reports
              mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Click `Add source` to open the Sources wizard.
      4. Enter a name for the source and click `Next`.
      5. Select `Red Hat Openshift Container Platform` as the source type and Cost Management as the application. Click `Next`.
      6. Enter the cluster identifier into the cloud.redhat.com Sources wizard, and click `Next`.

          **Note:** The cluster identifier can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      7. In the cloud.redhat.com Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:082ad6124b5fb01cdb3f3e50752751254c8d7850961803dd5ef63ce352b5c502
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:a09b76b020abf2768b67a1680db1228124b0292c7fb957f9b75c749a5d0578b7
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:3291423766117f8399fb44407661558bc706ebbd7850d17c306803a5a2229b2c
name: koku-metrics-operator.v0.9.5
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.5
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:6aba05ac027d1a49a36f99f161515d361703ac1b0466e31bb34bc7c3cc269550
      createdAt: "2021-03-17T19:09:49Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # v0.9.5 Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', '3600']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Click `Add source` to open the Sources wizard.
      4. Enter a name for the source and click `Next`.
      5. Select `Red Hat Openshift Container Platform` as the source type and Cost Management as the application. Click `Next`.
      6. Enter the cluster identifier into the cloud.redhat.com Sources wizard, and click `Next`.

          **Note:** The cluster identifier can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      7. In the cloud.redhat.com Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:3291423766117f8399fb44407661558bc706ebbd7850d17c306803a5a2229b2c
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:6aba05ac027d1a49a36f99f161515d361703ac1b0466e31bb34bc7c3cc269550
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:e6497bc0b1040b30dfe45c2781f1e9eaceeb63a508bcfd3bfa7f095067896ef4
name: koku-metrics-operator.v0.9.6
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.6
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:520a852663a629a78df4328573b629102d269587245c44f7559e54cd30e90bb1
      createdAt: "2021-04-01T16:48:59Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', '3600']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:e6497bc0b1040b30dfe45c2781f1e9eaceeb63a508bcfd3bfa7f095067896ef4
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:520a852663a629a78df4328573b629102d269587245c44f7559e54cd30e90bb1
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:cb045294db730ac83beae66908998ec8c9b9540dad0ea9a1059141ac117c1a0b
name: koku-metrics-operator.v0.9.7
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.7
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:50fd60d011a700edf41e53f69ea4717b31b26ceb1f9e079b1d4372570c8f9d13
      createdAt: "2021-04-13T20:39:31Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', '3600']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:cb045294db730ac83beae66908998ec8c9b9540dad0ea9a1059141ac117c1a0b
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:50fd60d011a700edf41e53f69ea4717b31b26ceb1f9e079b1d4372570c8f9d13
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:cffbef9a66aaff3ecb8d5dc8fc6a1c54b63a48bb5c2719a3d73dbdf88f778acf
name: koku-metrics-operator.v0.9.8
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 0.9.8
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:6c0b63c1e94141f501afe1b46142876fba7ae946b3c1983bff950e4b82a1a444
      createdAt: "2021-07-28T16:24:29Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v0.19.4
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', '3600']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:cffbef9a66aaff3ecb8d5dc8fc6a1c54b63a48bb5c2719a3d73dbdf88f778acf
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:6c0b63c1e94141f501afe1b46142876fba7ae946b3c1983bff950e4b82a1a444
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:c196edc27494d019b1380920bfc9bdb29da0f4cdd9e6d0f194f8b28c9263ddb6
name: koku-metrics-operator.v1.1.1
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.1
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:da062c74a576ba7314b16a12fb628d5147edabe66293e021d7261b3e65c9824c
      createdAt: "2021-12-09T21:08:57Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:c196edc27494d019b1380920bfc9bdb29da0f4cdd9e6d0f194f8b28c9263ddb6
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:da062c74a576ba7314b16a12fb628d5147edabe66293e021d7261b3e65c9824c
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:74519466010b2fa6f06e8d584f5ab7fac3eb7a0a6a5796bf956d97e7036e6621
name: koku-metrics-operator.v1.1.2
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.2
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:db8bd2e848df4bce714ad5e7b8a414cc91edc4749e0fa7f951304d07c02852ba
      createdAt: "2021-12-15T20:28:18Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/getting_started_with_cost_management/assembly_introduction_cost_management) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [cloud.redhat.com](https://cloud.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in cloud.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in cloud.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to cloud.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to cloud.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [cloud.redhat.com](https://cloud.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [cloud.redhat.com](https://cloud.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the cloud.redhat.com platform, open the [Sources menu](https://cloud.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [cloud.redhat.com](https://cloud.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:74519466010b2fa6f06e8d584f5ab7fac3eb7a0a6a5796bf956d97e7036e6621
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:db8bd2e848df4bce714ad5e7b8a414cc91edc4749e0fa7f951304d07c02852ba
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2e6d26e072f6218933d04f1ec195b59440b5b7314db702665217c3b544640821
name: koku-metrics-operator.v1.1.3
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.3
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:9cc13ad5cf9d0572eaa3887374dd5659459a7ca75b5d83c2498635cd2aa7fcfa
      createdAt: "2022-01-18T20:00:43Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2e6d26e072f6218933d04f1ec195b59440b5b7314db702665217c3b544640821
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:9cc13ad5cf9d0572eaa3887374dd5659459a7ca75b5d83c2498635cd2aa7fcfa
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:196d7305e5b58276acc1319664c77cda11fb6860b48aaf8f73e2d8b7ab18ac1c
name: koku-metrics-operator.v1.1.4
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.4
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:d254d58685d0495bd404cb740084758a5bcd80b1aa5ecee66b5608801d43feb5
      createdAt: "2022-01-25T19:02:20Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:196d7305e5b58276acc1319664c77cda11fb6860b48aaf8f73e2d8b7ab18ac1c
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:d254d58685d0495bd404cb740084758a5bcd80b1aa5ecee66b5608801d43feb5
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:f7413c7d593a84c486f03c4fe5384b4cd9f9f1f8822dd44aef42532d561f2106
name: koku-metrics-operator.v1.1.5
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.5
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:248f0cfa043d3637d3c7210390f5b4b916a85ddc9cb04cfdb1138abeeeaa6ae6
      createdAt: "2022-05-11T13:49:37Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.19.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/4.5/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      For more information, reach out to <cost-mgmt@redhat.com>.
      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:f7413c7d593a84c486f03c4fe5384b4cd9f9f1f8822dd44aef42532d561f2106
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:248f0cfa043d3637d3c7210390f5b4b916a85ddc9cb04cfdb1138abeeeaa6ae6
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2c54120a2f05d5ebfa66cf6be4457edd9d7d03d7f46400abc893749ab044d50d
name: koku-metrics-operator.v1.1.6
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.6
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:812b3be055f76913e0e00ef3bccb3c866bbc93e49fa439556d6298f83492fc6f
      createdAt: "2022-06-28T15:17:37Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
           affinity:
             podAffinity:
               requiredDuringSchedulingIgnoredDuringExecution:
               - labelSelector:
                   matchExpressions:
                   - key: app
                     operator: In
                     values:
                     - koku-metrics-operator
                 topologyKey: kubernetes.io/hostname
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:2c54120a2f05d5ebfa66cf6be4457edd9d7d03d7f46400abc893749ab044d50d
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:812b3be055f76913e0e00ef3bccb3c866bbc93e49fa439556d6298f83492fc6f
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:60c4ae8c230f823317fe8c8321843c68ae7e86ce91158155ee898ff55e72b68d
name: koku-metrics-operator.v1.1.7
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.7
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:4bebd4f6a2bc65732c2d9b488931669312669387b196e64ef0c0afb4180d2c3f
      createdAt: "2022-07-05T16:48:40Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.10.0+git
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:60c4ae8c230f823317fe8c8321843c68ae7e86ce91158155ee898ff55e72b68d
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:4bebd4f6a2bc65732c2d9b488931669312669387b196e64ef0c0afb4180d2c3f
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:553b821ddac33ae37b9146ffbf39749ba6f6d39c71bcd4cb9ac0266df4337bf8
name: koku-metrics-operator.v1.1.8
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.8
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:39941913cb80c7a75ee5614e223f51634af13388a3865ec2c2d0663b5efbe484
      createdAt: "2022-10-10T17:06:23Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.23.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:553b821ddac33ae37b9146ffbf39749ba6f6d39c71bcd4cb9ac0266df4337bf8
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:39941913cb80c7a75ee5614e223f51634af13388a3865ec2c2d0663b5efbe484
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:fdc59a8d6af8d704d6da0184704d3fcd5d134bd9b7721d9ff43a24a3ea9cf8ee
name: koku-metrics-operator.v1.1.9
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.1.9
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:e7f7b47891330e589e9b39974a73063978b8badf7e479790f5839e82cbf17c26
      createdAt: "2022-11-30T17:43:04Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.25.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:fdc59a8d6af8d704d6da0184704d3fcd5d134bd9b7721d9ff43a24a3ea9cf8ee
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:e7f7b47891330e589e9b39974a73063978b8badf7e479790f5839e82cbf17c26
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:d9d671f97086a38b7c679eb33dcc5e4a6bd4119b5f7362d355dfaeb46addc904
name: koku-metrics-operator.v1.2.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 1.2.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {},
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:4d60286deb439e81fad78056dd483393b28940b276f1a9dfc755c94558484b8b
      createdAt: "2023-01-16T18:30:07Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.25.3
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360,
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://cloud.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:d9d671f97086a38b7c679eb33dcc5e4a6bd4119b5f7362d355dfaeb46addc904
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:4d60286deb439e81fad78056dd483393b28940b276f1a9dfc755c94558484b8b
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:baf117e80773a6741b09c891a7caa8ae39cf5be49ddf308e2ca66ee8e88850db
name: koku-metrics-operator.v2.0.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 2.0.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": "INSERT-SOURCE-NAME"
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:e0ec3fb3f8ebd9ce09e4c35622e955731f3b2d93d51b34c6b6435a6d2b630c4c
      createdAt: "2023-03-29T16:40:08Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.25.3
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift, used to gather the required information from the cluster. It is recommended to be installed in OpenShift 4.5+. This operator obtains OpenShift usage data by querying Prometheus and uploads it to cost management to be processed. The Operator queries Prometheus every hour to create metric reports, which are then packaged and uploaded to cost management at [console.redhat.com](https://console.redhat.com). For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to cost management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for cost management by:
      * Querying Prometheus to gather the necessary metrics for cost management.
      * Writing Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to cost management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for cost management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by cost management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with cost management that the payload was processed. After Ingress accepts the uploaded payload, the payload is removed from the operator and is gone forever. If the data within the payload is not processed, a gap will be introduced in the usage metrics.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is filled. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` is used when the openshift-config pull-secret does not contain a token for `cloud.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic`. This parameter is required **only if** the authentication type is `basic`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: INSERT_SOURCE_NAME` -> The name of the Source the operator will create in `console.redhat.com`. The default is `INSERT_SOURCE_NAME` which is a placeholder.
          * `create_source: false` -> Toggle for whether or not the operator will create the Source in `console.redhat.com`. The default is False. This parameter should be switched to True when a Source does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if a Source exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace `INSERT-SOURCE-NAME` with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace `INSERT-SOURCE-NAME` with the existing name, and leave `create_source` as false. This will allow the operator to confirm the source exists.
      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to cost management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Create source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat sources` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Sources wizard, review the details and click `Finish` to create the Source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:baf117e80773a6741b09c891a7caa8ae39cf5be49ddf308e2ca66ee8e88850db
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:e0ec3fb3f8ebd9ce09e4c35622e955731f3b2d93d51b34c6b6435a6d2b630c4c
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:53560a00c6af00a188fb27f9684a7ff75b0d159c79559dd92686b2c3218302e9
name: koku-metrics-operator.v3.0.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.0.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:3f8fcc51d18214f1391592d518864b6099b16632d1e1fa3bf1c1803e0da81078
      createdAt: "2023-09-07T21:30:30Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.28.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` is used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic`. This parameter is required **only if** the authentication type is `basic`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the source the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the source in `console.redhat.com`. The default is False. This parameter should be switched to True when a source does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if a source exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the source exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a Source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating a source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:53560a00c6af00a188fb27f9684a7ff75b0d159c79559dd92686b2c3218302e9
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:3f8fcc51d18214f1391592d518864b6099b16632d1e1fa3bf1c1803e0da81078
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:c7c8463117fb866407a842de37331c81e6fc8f4069d22bc5aa2300c81d900e2e
name: koku-metrics-operator.v3.0.1
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.0.1
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:8a303e480260600315a4a13b0e6c47ef69f78354d4ba6938cd76b4da506423be
      createdAt: "2023-10-17T15:47:35Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.32.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create a source in console.redhat.com. A source is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * A source **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` is used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic`. This parameter is required **only if** the authentication type is `basic`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the source the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the source in `console.redhat.com`. The default is False. This parameter should be switched to True when a source does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if a source exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` is the preferred authentication method, a Secret must be created which holds username and password credentials:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys: `username` and `password` (all lowercase). The values for these keys correspond to console.redhat.com credentials.
      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

      3. To configure the koku-metrics-operator to create a cost management source, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the source to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the source already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the source exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create a Source
      In a restricted network, the `koku-metrics-operator` cannot automatically create a source. This process must be done manually. In the console.redhat.com platform, open the [Sources menu](https://console.redhat.com/settings/sources/) to begin adding an OpenShift source to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating a source:
      1. Navigate to the Sources menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` source:
          * give the source a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:c7c8463117fb866407a842de37331c81e6fc8f4069d22bc5aa2300c81d900e2e
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:8a303e480260600315a4a13b0e6c47ef69f78354d4ba6938cd76b4da506423be
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:d98b4fdc334361dc00db3c72f8f67b5de21c243bf5efb8eca0232c9be285687e
name: koku-metrics-operator.v3.1.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.1.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:abb24dd00a1265009c0e48756a2778432f1b99c2caacc62270821f93d77c3244
      createdAt: "2023-12-06T12:25:53Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["Disconnected"]'
      operators.operatorframework.io/builder: operator-sdk-v1.31.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v2
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: "# Koku Metrics Operator\n## Introduction\nThe `koku-metrics-operator`
      is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service)
      service for Openshift. The operator runs on the latest supported versions of
      Openshift. This operator obtains OpenShift usage data by querying Prometheus
      every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com)
      to be processed. For more information, reach out to <costmanagement@redhat.com>.\n\nThis
      operator is capable of functioning within a disconnected/restricted network
      (aka air-gapped mode). In this mode, the operator will store the packaged reports
      for manual retrieval instead of being uploaded to Cost Management. Documentation
      for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).\n\n##
      Features and Capabilities\n#### Metrics collection:\nThe Koku Metrics Operator
      (`koku-metrics-operator`) collects the metrics required for Cost Management
      by:\n* Querying Prometheus to gather the necessary metrics for Cost Management.\n*
      Writing the results of Prometheus queries to CSV report files.\n* Packaging
      the CSV report files into tarballs.\n\n#### Additional Capabilities:\n* Resource
      Optimization metrics collection.\n* The operator can be configured to gather
      all previous data within the configured retention period or a maximum of 90
      days. The default data collection period is the 14 previous days. This setting
      is only applicable to newly created KokuMetricsConfigs.\n* The operator can
      be configured to automatically upload the packaged reports to Cost Management
      through Red Hat Insights Ingress service.\n* The operator can create an integration
      in console.redhat.com. An integration is required for Cost Management to process
      the uploaded packages.\n* PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig
      CR can accept a PVC definition and the operator will create and mount the PVC.
      If one is not provided, a default PVC will be created.\n* Restricted network
      installation: this operator can function on a restricted network. In this mode,
      the operator stores the packaged reports for manual retrieval.\n\n## New in
      v3.1.0:\n* Add service-account authentication type.\n* __Deprecation Notice:__
      Basic authentication is deprecated and will be removed in a future version of
      the operator.\n\n## New in v3.0.0:\n* Daily report generation: Operator versions
      prior to v3.0.0 generated sequential reports. Now, reports are generated starting
      at 0:00 UTC. Any payloads generated throughout a given day will contain all
      data starting from 0:00 UTC. Once the next day starts, the previous day's reports
      are packaged, and the new report again starts at 0:00 UTC for the current day.\n*
      Failed query retry: In an attempt to prevent missing data, the operator will
      retry queries from the last successful query time, up to 5 times.\n\n## New
      in v2.0.0:\n* Adds metrics and report generation for resource optimization.
      This feature will collect additional usage metrics and create a new report in
      the payload. These metrics are enabled by default, but can be disabled by setting
      `disable_metrics_collection_resource_optimization` to `true`.\n* Collect all
      available Prometheus data upon CR creation. This feature only applies to newly
      created KokuMetricsConfigs. The operator will check the monitoring stack configuration
      in the `openshift-monitoring` namespace. The operator will use the `retention`
      period set in the `cluster-monitoring-config` ConfigMap if defined, up to a
      maximum of 90 days. Otherwise it will fall back to collecting 14 days of data,
      if available. This data collection may be disabled by setting `collect_previous_data`
      to `false`. Turning this feature off results in the operator collecting metrics
      from the time the KokuMetricsConfig is created, forward.\n\n## Limitations and
      Pre-Requisites\n#### Limitations (Potential for metrics data loss)\n* An integration
      **must** exist in console.redhat.com for an uploaded payload to be processed
      by Cost Management. The operator sends the payload to the Red Hat Insights Ingress
      service which usually returns successfully, but the operator does not currently
      confirm with Cost Management that the payload was processed. After Ingress accepts
      the uploaded payload, it is deleted from the operator. If the data within the
      payload is not processed, a gap will be introduced in the usage metrics. Data
      may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`,
      and setting `collect_previous_data: true`. This re-collection of data will gather
      all data stored in Prometheus, up to 90 days.\n\n**Note** The following limitations
      are specific to operators configured to run in a restricted network:\n* The
      `koku-metrics-operator` will not be able to generate new reports if the PVC
      storage is full. If this occurs, the reports must be manually deleted from the
      PVC so that the operator can function as normal.\n* The default report retention
      is 30 reports (about one week's worth of data). The reports must be manually
      downloaded and uploaded to console.redhat.com every week, or they will be deleted
      and the data will be lost.\n\n#### Storage configuration prerequisite\nThe operator
      will attempt to create and use the following PVC when installed:\n\n      volume_claim_template:\n
      \       apiVersion: v1\n        kind: PersistentVolumeClaim\n        metadata:\n
      \         name: koku-metrics-operator-data\n        spec:\n          accessModes:\n
      \           - ReadWriteOnce\n          resources:\n            requests:\n              storage:
      10Gi\n\nIf a different PVC should be utilized, a valid PVC should be specified
      in the KokuMetricsConfig CR as described in the appropriate section below. The
      PVC to be used may exist already, or the operator will attempt to create it.\n\nTo
      use the default specification, the follow assumptions must be met:\n1. A default
      StorageClass is defined.\n2. Dynamic provisioning for that default StorageClass
      is enabled.\n\nIf these assumptions are not met, the operator will not deploy
      correctly. In these cases, storage must be manually configured. After configuring
      storage, a valid PVC template should be supplied in the `volume_claim_template`
      spec of the KokuMetricsConfig CR.\n\n## Configurable parameters:\n  * `authentication`:\n
      \   * `type: token` -> The authentication method for connecting to `console.redhat.com`.
      The default and preferred method is `token`. `basic` (deprecated) and `service-account`
      authentication methods are used when the openshift-config pull-secret does not
      contain a token for `console.redhat.com`.\n    * `secret_name` -> The Secret
      used by the operator when the authentication type is `basic` (deprecated) or
      `service-account`. This parameter is required **only if** the authentication
      type is `basic` (deprecated) or `service-account`.\n  * `packaging`:\n    *
      `max_reports_to_store: 30` -> The number of reports to store when configured
      in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When
      the operator is not configured in air-gapped mode, this parameter has no effect.
      Reports are removed as soon as they are uploaded.\n    * `max_size: 100` ->
      The maximum size for packaged files in Megabytes prior to compression. The default
      is 100, with a minimum of 1 and maximum of 100.\n  * `prometheus_config`:\n
      \   * `collect_previous_data: true` -> Toggle for collecting all available data
      in Prometheus **upon KokuMetricsConfig creation** (This parameter will start
      to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not
      have any effect unless the KokuMetricsConfig is deleted and recreated). The
      default is `true`. The operator will first look for a `retention` period in
      the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace
      and gather data over this time period up to a maximum of 90 days. If this configuration
      is not set, the default is 14 days. (New in v2.0.0)\n    * `disable_metrics_collection_cost_management:
      false` -> Toggle for disabling the collection of metrics for Cost Management.
      The default is false. (New in v2.0.0)\n    * `disable_metrics_collection_resource_optimization:
      false` -> Toggle for disabling the collection of metrics for Resource Optimization.
      The default is false. (New in v2.0.0)\n    * `context_timeout: 120` -> The time
      in seconds before Prometheus queries timeout due to exceeding context timeout.
      The default is 120, with a minimum of 10 and maximum of 180.\n  * `source`:\n
      \   * `name: ''` -> The name of the integration the operator will create in
      `console.redhat.com`. If the name value is empty, the default intergration name
      is the **cluster id**.\n    * `create_source: false` -> Toggle for whether or
      not the operator will create the integration in `console.redhat.com`. The default
      is False. This parameter should be switched to True when an integration does
      not already exist in `console.redhat.com` for this cluster.\n    * `check_cycle:
      1440` -> The time in minutes to wait between checking if an integration exists
      for this cluster. The default is 1440 minutes (24 hrs).\n  * `upload`:\n    *
      `upload_cycle: 360` -> The time in minutes between payload uploads. The default
      is 360 (6 hours).\n    * `upload_toggle: true` -> Toggle to turn upload on or
      off -> true means upload, false means do not upload (false == air-gapped mode).
      The default is `true`.\n    * `upload_wait` -> The amount of time (in seconds)
      to pause before uploading a payload. The default is a random number between
      0 and 35. This is used to decrease service load, but may be set to `0` if desired.\n
      \ * `volume_claim_template` -> see the \"Storage configuration prerequisite\"
      section above.\n\n## Configure the koku-metrics-operator\n**Note** There are
      separate instructions for configuring the `koku-metrics-operator` to run in
      a restricted network.\n##### Configure authentication\nThe default authentication
      for the operator is `token`. No further steps are required to configure token
      authentication. If `basic` (deprecated) or `service-account` is the preferred
      authentication method, a Secret which holds the credentials must be created:\n1.
      On the left navigation pane, select `Workloads` -> `Secrets` -> select Project:
      `koku-metrics-operator` -> `Create` -> `Key/Value Secret`\n2. Give the Secret
      a name and add 2 keys (all lowercase) for the respective authentication type.
      The values for these keys correspond to console.redhat.com credentials:\n    *
      basic auth (deprecated): `username` and `password`\n    * service-account auth:
      `client_id` and `client_secret` \n\n3. Select `Create`.\n##### Create the KokuMetricsConfig\nConfigure
      the koku-metrics-operator by creating a `KokuMetricsConfig`.\n1. On the left
      navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator`
      -> `KokuMetricsConfig` -> `Create Instance`.\n2. For `basic` (deprecated) or
      `service-account` authentication, edit the following values in the spec:\n    *
      Replace `authentication: type:` with `basic` or `service-account`.\n    * Add
      the `secret_name` field under `authentication`, and set it equal to the name
      of the authentication Secret that was created above. The spec should look similar
      to the following:\n\n        * for basic auth type (deprecated)\n        ```\n
      \         authentication:\n            secret_name: SECRET-NAME\n            type:
      basic\n        ```\n          \n        * for service-account auth type\n        ```\n
      \         authentication:\n            secret_name: SECRET-NAME\n            type:
      service-account\n        ```\n\n3. To configure the koku-metrics-operator to
      create a cost management integration, edit the following values in the `source`
      field:\n    * Replace the `name` field value with the preferred name of the
      integration to be created.\n    * Replace the `create_source` field value with
      `true`.\n\n    **Note:** if the integration already exists, replace the empty
      string value of the `name` field with the existing name, and leave `create_source`
      as false. This will allow the operator to confirm that the integration exists.\n\n4.
      If not specified, the operator will create a default PersistentVolumeClaim called
      `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator
      to use or create a different PVC, edit the following in the spec:\n    * Add
      the desired configuration to the `volume_claim_template` field in the spec:\n\n
      \     ```\n        volume_claim_template:\n          apiVersion: v1\n          kind:
      PersistentVolumeClaim\n          metadata:\n            name: <insert-name>\n
      \         spec:\n            accessModes:\n              - ReadWriteOnce\n            resources:\n
      \             requests:\n                storage: 10Gi\n      ```\n\n    **Note:**
      If using the YAML View, the `volume_claim_template` field must be added to the
      spec\n5. Select `Create`.\n\n# Restricted Network Usage (disconnected/air-gapped
      mode)\n## Installation\nTo install the `koku-metrics-operator` in a restricted
      network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).
      The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest`
      Index. If pruning the index before pushing to the mirrored registry, keep the
      `koku-metrics-operator` package.\n\nWithin a restricted network, the operator
      queries prometheus to gather the necessary usage metrics, writes the query results
      to CSV files, and packages the reports for storage in the PVC. These reports
      then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).\n\n##
      Configure the koku-metrics-operator for a restricted network\n##### Create the
      KokuMetricsConfig\nConfigure the koku-metrics-operator by creating a `KokuMetricsConfig`.\n1.
      On the left navigation pane, select `Operators` -> `Installed Operators` ->
      `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.\n2. Specify
      the desired storage. If not specified, the operator will create a default Persistent
      Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure
      the koku-metrics-operator to use or create a different PVC, edit the following
      in the spec:\n    * Add the desired configuration to the `volume_claim_template`
      field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim`
      may be defined here):\n\n      ```\n        volume_claim_template:\n          apiVersion:
      v1\n          kind: PersistentVolumeClaim\n          metadata:\n            name:
      <insert-name>\n          spec:\n            storageClassName: <insert-class-name>\n
      \           accessModes:\n              - ReadWriteOnce\n            resources:\n
      \             requests:\n                storage: 10Gi\n      ```\n\n    **Note:**
      If using the YAML View, the `volume_claim_template` field must be added to the
      spec\n3. (Optional) Specify the desired report retention. The operator will
      retain 30 reports by default. This corresponds to approximately one week's worth
      of data if using the default packaging cycle. To modify the number of retained
      reports:\n    * Change the `packaging` spec field `max_reports_to_store` to
      the desired number of reports to retain. Once this max number is reached, the
      operator will start removing the oldest packages remaining on the PVC:\n\n      ```\n
      \       packaging:\n          max_size_MB: 100\n          max_reports_to_store:
      30\n      ```\n\n    **Note:** The number of retained reports directly affects
      the frequency that reports must be manually downloaded from the PVC. Take caution
      in setting this to a higher number of reports, as the operator cannot write
      data to the PVC if the storage is full.\n4. To configure the operator to perform
      in a restricted network, set the `upload_toggle` to `false`:\n\n  ```\n    upload:\n
      \     upload_cycle: 360\n      upload_toggle: false\n  ```\n\n5. Select `Create`.\n\n##
      Download reports from the Operator & clean up the PVC\nIf the `koku-metrics-operator`
      is configured to run in a restricted network, the metric reports will not automatically
      upload to cost managment. Instead, they need to be manually copied from the
      PVC for upload to [console.redhat.com](https://console.redhat.com). The default
      configuration saves one week of reports which means the process of downloading
      and uploading reports should be repeated weekly to prevent loss of metrics data.
      To download the reports, complete the following steps:\n1. Create the following
      Pod, ensuring the `claimName` matches the PVC containing the report data:\n\n
      \ ```\n    kind: Pod\n    apiVersion: v1\n    metadata:\n      name: volume-shell\n
      \     namespace: koku-metrics-operator\n      labels:\n        app: koku-metrics-operator\n
      \   spec:\n      volumes:\n      - name: koku-metrics-operator-reports\n        persistentVolumeClaim:\n
      \         claimName: koku-metrics-operator-data\n      containers:\n      -
      name: volume-shell\n        image: busybox\n        command: ['sleep', 'infinity']\n
      \       volumeMounts:\n        - name: koku-metrics-operator-reports\n          mountPath:
      /tmp/koku-metrics-operator-reports\n  ```\n\n2. Use rsync to copy all of the
      files ready for upload from the PVC to a local folder:\n\n  ```\n  $ oc rsync
      volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder\n
      \ ```\n\n3. Once confirming that the files have been successfully copied, use
      rsh to connect to the pod and delete the contents of the upload folder so that
      they are no longer in storage:\n\n  ```\n  $ oc rsh volume-shell\n  $ rm /tmp/koku-metrics-operator-reports/upload/*\n
      \ ```\n\n4. (Optional) Delete the pod that was used to connect to the PVC:\n\n
      \ ```\n  $ oc delete -f volume-shell.yaml\n  ```\n\n## Create an Integration\nIn
      a restricted network, the `koku-metrics-operator` cannot automatically create
      an integration. This process must be done manually. In the console.redhat.com
      platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/)
      to begin adding an OpenShift integration to Cost Management:\n\nPrerequisites:\n*
      The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster
      Overview page, or the cluster Help > About.\n\nCreating an integration:\n1.
      Navigate to the Integrations menu\n2. Select the `Red Hat` tab\n3. Create a
      new `Red Hat Openshift Container Platform` integration:\n    * give the integration
      a unique name\n    * add the Cost Management application\n    * add the cluster
      identifier\n4. In the Source wizard, review the details and click `Finish` to
      create the source.\n\n## Upload the reports to cost managment\nUploading reports
      to cost managment is done through curl:\n\n    $ curl -vvvv -F \"file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz\"
      \ https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS\n\nwhere
      `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com),
      and `FILE_NAME` is the name of the report to upload."
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/openshift-community-operators/koku-metrics-operator@sha256:d98b4fdc334361dc00db3c72f8f67b5de21c243bf5efb8eca0232c9be285687e
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:abb24dd00a1265009c0e48756a2778432f1b99c2caacc62270821f93d77c3244
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:3f98fd469ce1588f832d058fa2428214134713261104d14f4d8be129b766e5b8
name: koku-metrics-operator.v3.2.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.2.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      com.redhat.openshift.versions: "4.12"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:fa59df2b2ea01274e45dd9c207fc2b86dd1dd1ee6ce54d904ead0a63120fafb8
      createdAt: "2024-02-29T15:52:18Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.33.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |-
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures
      * add liveness and readiness probes to controller Pod
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/)

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:3f98fd469ce1588f832d058fa2428214134713261104d14f4d8be129b766e5b8
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:fa59df2b2ea01274e45dd9c207fc2b86dd1dd1ee6ce54d904ead0a63120fafb8
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:c30939e5a4af679897b1e1b088745ce1d95d04f4a19f59ee3807cfe4f8e52be6
name: koku-metrics-operator.v3.2.1
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.2.1
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:197346c3e394b38034d47d3aa2736144b8199997e1fee6843d29c903ed6ba247
      createdAt: "2024-04-03T14:22:53Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.33.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.2.1:
      * The minimum supported configuration for `upload_cycle` is now 60 (minutes).
      * (Bugfix) many-to-many matching not allowed query fix.
      * (Bugfix) Sequentially collect data during initial install.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures.
      * add liveness and readiness probes to controller Pod.
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/).

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours), minimum is 60 (1 hour).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz"  https://console.redhat.com/api/ingress/v1/upload -u USERNAME:PASS

      where `USERNAME` and `PASS` correspond to the user credentials for [console.redhat.com](https://console.redhat.com), and `FILE_NAME` is the name of the report to upload.
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:c30939e5a4af679897b1e1b088745ce1d95d04f4a19f59ee3807cfe4f8e52be6
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:197346c3e394b38034d47d3aa2736144b8199997e1fee6843d29c903ed6ba247
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:f3f2e344b25494fec027b05c1be0914cb386ffaed3a67268a00949ca39150ee3
name: koku-metrics-operator.v3.3.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.3.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:0c8091f0c04593c19249755bde418cc09e5d30cc55c6cbff2c5b60bdf60dfde9
      createdAt: "2024-05-31T16:09:13Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.33.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.3.0:
      * Storage reports now contain `node`, `csi_driver`, and `csi_volume_handle` fields.
      * The PVC capacity is now populated using the `kube_persistentvolume_capacity_bytes` metric instead of `kubelet_volume_stats_capacity_bytes`.
      * To receive resource optimization recommendations for your namespaces, you must now first enable each namespace. To enable a namespace, label it with `insights_cost_management_optimizations='true'`. In the CLI, run:
        ```
          oc label namespace NAMESPACE insights_cost_management_optimizations="true" --overwrite=true
        ```
      * __DEPRECATION NOTICE__: Basic authentication is deprecated and will not be supported beyond December 31, 2024. If the default token authentication method cannot be used, you must switch to [service account](https://console.redhat.com/iam/service-accounts) authentication ([more on creating a service account](https://access.redhat.com/articles/7036194)). Once you have created your service account, follow [this documentation](https://access.redhat.com/documentation/en-us/cost_management_service/1-latest/html-single/integrating_openshift_container_platform_data_into_cost_management/index#service-account-authentication_adding-an-ocp-int) on how to configure your operator to use service account authentication. Service-accounts must also be used if manually uploading payloads to console.redhat.com.

      ## New in v3.2.1:
      * The minimum supported configuration for `upload_cycle` is now 60 (minutes).
      * (Bugfix) many-to-many matching not allowed query fix.
      * (Bugfix) Sequentially collect data during initial install.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures.
      * add liveness and readiness probes to controller Pod.
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/).

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours), minimum is 60 (1 hour).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz" https://console.redhat.com/api/ingress/v1/upload -H "Authorization: Bearer ${ACCESS_TOKEN}"

      where `FILE_NAME` is the name of the report to upload. The `ACCESS_TOKEN` is acquired using a [service-account](https://access.redhat.com/articles/7036194).
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:f3f2e344b25494fec027b05c1be0914cb386ffaed3a67268a00949ca39150ee3
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:0c8091f0c04593c19249755bde418cc09e5d30cc55c6cbff2c5b60bdf60dfde9
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:5c501ae285fe463608c4a2ca2d58bd9bb96b8faee7caef1076eee607eeaeb664
name: koku-metrics-operator.v3.3.1
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.3.1
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:fe2a887778e30850b94983038ed621d8df6e45d1028f3d1110cc8aa20439bedd
      createdAt: "2024-08-09T15:42:34Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.35.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.3.1:
      * Optimize memory usage when reading CSV files.

      ## New in v3.3.0:
      * Storage reports now contain `node`, `csi_driver`, and `csi_volume_handle` fields.
      * The PVC capacity is now populated using the `kube_persistentvolume_capacity_bytes` metric instead of `kubelet_volume_stats_capacity_bytes`.
      * To receive resource optimization recommendations for your namespaces, you must now first enable each namespace. To enable a namespace, label it with `insights_cost_management_optimizations='true'`. In the CLI, run:
        ```
          oc label namespace NAMESPACE insights_cost_management_optimizations="true" --overwrite=true
        ```
      * __DEPRECATION NOTICE__: Basic authentication is deprecated and will not be supported beyond December 31, 2024. If the default token authentication method cannot be used, you must switch to [service account](https://console.redhat.com/iam/service-accounts) authentication ([more on creating a service account](https://access.redhat.com/articles/7036194)). Once you have created your service account, follow [this documentation](https://access.redhat.com/documentation/en-us/cost_management_service/1-latest/html-single/integrating_openshift_container_platform_data_into_cost_management/index#service-account-authentication_adding-an-ocp-int) on how to configure your operator to use service account authentication. Service-accounts must also be used if manually uploading payloads to console.redhat.com.

      ## New in v3.2.1:
      * The minimum supported configuration for `upload_cycle` is now 60 (minutes).
      * (Bugfix) many-to-many matching not allowed query fix.
      * (Bugfix) Sequentially collect data during initial install.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures.
      * add liveness and readiness probes to controller Pod.
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/).

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours), minimum is 60 (1 hour).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz" https://console.redhat.com/api/ingress/v1/upload -H "Authorization: Bearer ${ACCESS_TOKEN}"

      where `FILE_NAME` is the name of the report to upload. The `ACCESS_TOKEN` is acquired using a [service-account](https://access.redhat.com/articles/7036194).
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:5c501ae285fe463608c4a2ca2d58bd9bb96b8faee7caef1076eee607eeaeb664
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:fe2a887778e30850b94983038ed621d8df6e45d1028f3d1110cc8aa20439bedd
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:9114f72f6adca60e18616786019d680883bb1c1dc88d317e7adeeec787054469
name: koku-metrics-operator.v3.3.2
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: koku-metrics-cfg.openshift.io
    kind: KokuMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 3.3.2
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "koku-metrics-cfg.openshift.io/v1beta1",
            "kind": "KokuMetricsConfig",
            "metadata": {
              "name": "kokumetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:c1b430cb1d699289c05fc1944d06bd6e6d09a886ab15a4f7b01f779b8ffef9b7
      createdAt: "2024-11-05T20:59:20Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/cnf: "false"
      features.operators.openshift.io/cni: "false"
      features.operators.openshift.io/csi: "false"
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.35.0
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: KokuMetricsConfig is the Schema for the kokumetricsconfig API
        displayName: Koku Metrics Config
        kind: KokuMetricsConfig
        name: kokumetricsconfigs.koku-metrics-cfg.openshift.io
        version: v1beta1
    description: |
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v3.3.2:
      * Leader election settings are now configurable via environment variables. These variables can be modified in the operator [Subscription](https://github.com/operator-framework/operator-lifecycle-manager/blob/5a01f50258003e248bd5630df0837fe0bb0f1cb7/doc/design/subscription-config.md). The values should be specified as durations in seconds in the format `<number-of-seconds>s`. The default values for `LEADER_ELECTION_LEASE_DURATION`, `LEADER_ELECTION_RENEW_DEADLINE`, and `LEADER_ELECTION_RETRY_PERIOD` are '60s', '30s', and '5s', respectively.

        ```
        kind: Subscription
        metadata:
        ...
        spec:
          ...
          config:
            env:
            - name: LEADER_ELECTION_LEASE_DURATION
              value: "60s"
            - name: LEADER_ELECTION_RENEW_DEADLINE
              value: "30s"
            - name: LEADER_ELECTION_RETRY_PERIOD
              value: "5s"
        ```

      ## New in v3.3.1:
      * Optimize memory usage when reading CSV files.

      ## New in v3.3.0:
      * Storage reports now contain `node`, `csi_driver`, and `csi_volume_handle` fields.
      * The PVC capacity is now populated using the `kube_persistentvolume_capacity_bytes` metric instead of `kubelet_volume_stats_capacity_bytes`.
      * To receive resource optimization recommendations for your namespaces, you must now first enable each namespace. To enable a namespace, label it with `insights_cost_management_optimizations='true'`. In the CLI, run:
        ```
          oc label namespace NAMESPACE insights_cost_management_optimizations="true" --overwrite=true
        ```
      * __DEPRECATION NOTICE__: Basic authentication is deprecated and will not be supported beyond December 31, 2024. If the default token authentication method cannot be used, you must switch to [service account](https://console.redhat.com/iam/service-accounts) authentication ([more on creating a service account](https://access.redhat.com/articles/7036194)). Once you have created your service account, follow [this documentation](https://access.redhat.com/documentation/en-us/cost_management_service/1-latest/html-single/integrating_openshift_container_platform_data_into_cost_management/index#service-account-authentication_adding-an-ocp-int) on how to configure your operator to use service account authentication. Service-accounts must also be used if manually uploading payloads to console.redhat.com.

      ## New in v3.2.1:
      * The minimum supported configuration for `upload_cycle` is now 60 (minutes).
      * (Bugfix) many-to-many matching not allowed query fix.
      * (Bugfix) Sequentially collect data during initial install.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures.
      * add liveness and readiness probes to controller Pod.
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/).

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours), minimum is 60 (1 hour).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz" https://console.redhat.com/api/ingress/v1/upload -H "Authorization: Bearer ${ACCESS_TOKEN}"

      where `FILE_NAME` is the name of the report to upload. The `ACCESS_TOKEN` is acquired using a [service-account](https://access.redhat.com/articles/7036194).
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator@sha256:9114f72f6adca60e18616786019d680883bb1c1dc88d317e7adeeec787054469
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:c1b430cb1d699289c05fc1944d06bd6e6d09a886ab15a4f7b01f779b8ffef9b7
  name: koku-metrics-operator
schema: olm.bundle
---
image: quay.io/community-operator-pipeline-prod/koku-metrics-operator:4.0.0
name: koku-metrics-operator.v4.0.0
package: koku-metrics-operator
properties:
- type: olm.gvk
  value:
    group: costmanagement-metrics-cfg.openshift.io
    kind: CostManagementMetricsConfig
    version: v1beta1
- type: olm.package
  value:
    packageName: koku-metrics-operator
    version: 4.0.0
- type: olm.csv.metadata
  value:
    annotations:
      alm-examples: |-
        [
          {
            "apiVersion": "costmanagement-metrics-cfg.openshift.io/v1beta1",
            "kind": "CostManagementMetricsConfig",
            "metadata": {
              "name": "costmanagementmetricscfg-sample-v1beta1"
            },
            "spec": {
              "authentication": {
                "type": "token"
              },
              "packaging": {
                "max_reports_to_store": 30,
                "max_size_MB": 100
              },
              "prometheus_config": {
                "collect_previous_data": true,
                "context_timeout": 120,
                "disable_metrics_collection_cost_management": false,
                "disable_metrics_collection_resource_optimization": false
              },
              "source": {
                "check_cycle": 1440,
                "create_source": false,
                "name": ""
              },
              "upload": {
                "upload_cycle": 360,
                "upload_toggle": true
              }
            }
          }
        ]
      capabilities: Seamless Upgrades
      categories: Monitoring
      certified: "false"
      containerImage: quay.io/project-koku/koku-metrics-operator@sha256:6881531e66c4c11c6a8bd60e535040d5c5974848dc6446297c1d9a5feef6f864
      createdAt: "2025-06-05T14:45:42Z"
      description: A Golang-based OpenShift Operator that generates and uploads OpenShift
        usage metrics to cost management.
      features.operators.openshift.io/cnf: "false"
      features.operators.openshift.io/cni: "false"
      features.operators.openshift.io/csi: "false"
      features.operators.openshift.io/disconnected: "true"
      features.operators.openshift.io/fips-compliant: "false"
      features.operators.openshift.io/proxy-aware: "true"
      features.operators.openshift.io/tls-profiles: "false"
      features.operators.openshift.io/token-auth-aws: "false"
      features.operators.openshift.io/token-auth-azure: "false"
      features.operators.openshift.io/token-auth-gcp: "false"
      operatorframework.io/initialization-resource: |-
        {
          "apiVersion": "costmanagement-metrics-cfg.openshift.io/v1beta1",
          "kind": "CostManagementMetricsConfig",
          "metadata": {
            "name": "costmanagementmetricscfg-sample-v1beta1"
          },
          "spec": {
            "authentication": {
              "token_url": "https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token",
              "type": "token"
            },
            "api_url": "https://console.redhat.com/",
            "packaging": {
              "max_reports_to_store": 30,
              "max_size_MB": 100
            },
            "upload": {
              "ingress_path": "/api/ingress/v1/upload",
              "upload_cycle": 360,
              "upload_toggle": true,
              "validate_cert": true
            },
            "prometheus_config": {
              "collect_previous_data": true,
              "context_timeout": 120,
              "disable_metrics_collection_cost_management": false,
              "disable_metrics_collection_resource_optimization": false,
              "service_address": "https://thanos-querier.openshift-monitoring.svc:9091",
              "skip_tls_verification": false
            },
            "source": {
              "check_cycle": 1440,
              "create_source": false,
              "name": "",
              "sources_path": "/api/sources/v1.0/"
            }
          }
        }
      operatorframework.io/suggested-namespace: koku-metrics-operator
      operators.openshift.io/infrastructure-features: '["disconnected", "proxy-aware"]'
      operators.operatorframework.io/builder: operator-sdk-v1.39.2
      operators.operatorframework.io/project_layout: go.kubebuilder.io/v4
      repository: https://github.com/project-koku/koku-metrics-operator
      support: Cost Management
    apiServiceDefinitions: {}
    crdDescriptions:
      owned:
      - description: CostManagementMetricsConfig is the Schema for the costmanagementmetricsconfig
          API
        displayName: Cost Management Metrics Config
        kind: CostManagementMetricsConfig
        name: costmanagementmetricsconfigs.costmanagement-metrics-cfg.openshift.io
        version: v1beta1
    description: |
      # Koku Metrics Operator
      ## Introduction
      The `koku-metrics-operator` is a component of the [cost managment](https://access.redhat.com/documentation/en-us/cost_management_service) service for Openshift. The operator runs on the latest supported versions of Openshift. This operator obtains OpenShift usage data by querying Prometheus every hour to create metric reports that it uploads to Cost Management at [console.redhat.com](https://console.redhat.com) to be processed. For more information, reach out to <costmanagement@redhat.com>.

      This operator is capable of functioning within a disconnected/restricted network (aka air-gapped mode). In this mode, the operator will store the packaged reports for manual retrieval instead of being uploaded to Cost Management. Documentation for installing an operator within a restricted network can be found [here](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html).

      ## Features and Capabilities
      #### Metrics collection:
      The Koku Metrics Operator (`koku-metrics-operator`) collects the metrics required for Cost Management by:
      * Querying Prometheus to gather the necessary metrics for Cost Management.
      * Writing the results of Prometheus queries to CSV report files.
      * Packaging the CSV report files into tarballs.

      #### Additional Capabilities:
      * Resource Optimization metrics collection.
      * The operator can be configured to gather all previous data within the configured retention period or a maximum of 90 days. The default data collection period is the 14 previous days. This setting is only applicable to newly created KokuMetricsConfigs.
      * The operator can be configured to automatically upload the packaged reports to Cost Management through Red Hat Insights Ingress service.
      * The operator can create an integration in console.redhat.com. An integration is required for Cost Management to process the uploaded packages.
      * PersistentVolumeClaim (PVC) configuration: The KokuMetricsConfig CR can accept a PVC definition and the operator will create and mount the PVC. If one is not provided, a default PVC will be created.
      * Restricted network installation: this operator can function on a restricted network. In this mode, the operator stores the packaged reports for manual retrieval.

      ## New in v4.0.0:
      * **Virtual Machine Metrics:** Adds capabilities for collecting metrics and generating reports for running virtual machines within your OpenShift environment.
      * **Progress towards FIPS 140 Compliance:** The operator is using the Go Cryptographic Module v1.0.0 to progress toward FIPS 140 compliance. Although this module is not validated at the time of this release, the operator aims to meet stricter security standards when the module does successfully achieve FIPS validation.
      * **API Name Change:** The Custom Resource Definition (CRD) for configuring the upstream `Koku Metrics Operator` was renamed from `KokuMetricsConfig` to `CostManagementMetricsConfig`.

      ### NOTE:
        * The API name change impacts only users of the upstream (community) Koku Metrics Operator.
        * The downstream (Red Hat-supported) Cost Management Metrics Operator is not impacted by this change and users should continue using their existing configurations.

      **Important Upgrade Instructions:**

        If you are upgrading the upstream Koku Metrics Operator to version 4.0.0 or higher, you must manually migrate your configuration. The operator will no longer recognize existing `KokuMetricsConfig` resources.

        To successfully upgrade and retain your operator's configuration, complete the following steps. You can use the provided `oc` commands replacing the angle brackets (`< >`) with your specific values:

        1. Backup existing configuration (recommended):

           Before you upgrade, retrieve the details of your current `KokuMetricsConfig` instance to help you recreate it with the new API name.

           ```
           oc get kokumetricsconfig -n koku-metrics-operator <your-config-name> -o yaml > koku-metrics-config-backup.yaml
           ```

        2. Delete the previous `KokuMetricsConfig` instance (recommended):

            After the operator is upgraded to `version 4.0.0`, delete any existing `KokuMetricsConfig` resources.

            ```
            oc delete kokumetricsconfig -n koku-metrics-operator <your-config-name>
            ```

        3. Create the new `CostManagementMetricsConfig` instance:

            Using the information from your backup (or a new configuration), create a new `CostManagementMetricsConfig` instance. Adjust the spec section based on your specific needs. For more information about configurations, [refer to the configurable parameters](#configurable-parameters).

        4. Apply your new configuration:

            ```
            oc apply -f <your-costmanagementmetricsconfig-file>.yaml -n koku-metrics-operator
            ```

      ## New in v3.3.2:
      * Leader election settings are now configurable via environment variables. These variables can be modified in the operator [Subscription](https://github.com/operator-framework/operator-lifecycle-manager/blob/5a01f50258003e248bd5630df0837fe0bb0f1cb7/doc/design/subscription-config.md). The values should be specified as durations in seconds in the format `<number-of-seconds>s`. The default values for `LEADER_ELECTION_LEASE_DURATION`, `LEADER_ELECTION_RENEW_DEADLINE`, and `LEADER_ELECTION_RETRY_PERIOD` are '60s', '30s', and '5s', respectively.

        ```
        kind: Subscription
        metadata:
        ...
        spec:
          ...
          config:
            env:
            - name: LEADER_ELECTION_LEASE_DURATION
              value: "60s"
            - name: LEADER_ELECTION_RENEW_DEADLINE
              value: "30s"
            - name: LEADER_ELECTION_RETRY_PERIOD
              value: "5s"
        ```

      ## New in v3.3.1:
      * Optimize memory usage when reading CSV files.

      ## New in v3.3.0:
      * Storage reports now contain `node`, `csi_driver`, and `csi_volume_handle` fields.
      * The PVC capacity is now populated using the `kube_persistentvolume_capacity_bytes` metric instead of `kubelet_volume_stats_capacity_bytes`.
      * To receive resource optimization recommendations for your namespaces, you must now first enable each namespace. To enable a namespace, label it with `insights_cost_management_optimizations='true'`. In the CLI, run:
        ```
          oc label namespace NAMESPACE insights_cost_management_optimizations="true" --overwrite=true
        ```
      * __DEPRECATION NOTICE__: Basic authentication is deprecated and will not be supported beyond December 31, 2024. If the default token authentication method cannot be used, you must switch to [service account](https://console.redhat.com/iam/service-accounts) authentication ([more on creating a service account](https://access.redhat.com/articles/7036194)). Once you have created your service account, follow [this documentation](https://access.redhat.com/documentation/en-us/cost_management_service/1-latest/html-single/integrating_openshift_container_platform_data_into_cost_management/index#service-account-authentication_adding-an-ocp-int) on how to configure your operator to use service account authentication. Service-accounts must also be used if manually uploading payloads to console.redhat.com.

      ## New in v3.2.1:
      * The minimum supported configuration for `upload_cycle` is now 60 (minutes).
      * (Bugfix) many-to-many matching not allowed query fix.
      * (Bugfix) Sequentially collect data during initial install.

      ## New in v3.2.0:
      * Support for amd64, arm64, ppc64le, s390x architectures.
      * add liveness and readiness probes to controller Pod.
      * update pod security settings so that the controller Pod can run in Restricted mode [more info](https://sdk.operatorframework.io/docs/best-practices/pod-security-standards/).

      ## New in v3.1.0:
      * Add service-account authentication type.
      * __Deprecation Notice:__ Basic authentication is deprecated and will be removed in a future version of the operator.

      ## New in v3.0.0:
      * Daily report generation: Operator versions prior to v3.0.0 generated sequential reports. Now, reports are generated starting at 0:00 UTC. Any payloads generated throughout a given day will contain all data starting from 0:00 UTC. Once the next day starts, the previous day's reports are packaged, and the new report again starts at 0:00 UTC for the current day.
      * Failed query retry: In an attempt to prevent missing data, the operator will retry queries from the last successful query time, up to 5 times.

      ## New in v2.0.0:
      * Adds metrics and report generation for resource optimization. This feature will collect additional usage metrics and create a new report in the payload. These metrics are enabled by default, but can be disabled by setting `disable_metrics_collection_resource_optimization` to `true`.
      * Collect all available Prometheus data upon CR creation. This feature only applies to newly created KokuMetricsConfigs. The operator will check the monitoring stack configuration in the `openshift-monitoring` namespace. The operator will use the `retention` period set in the `cluster-monitoring-config` ConfigMap if defined, up to a maximum of 90 days. Otherwise it will fall back to collecting 14 days of data, if available. This data collection may be disabled by setting `collect_previous_data` to `false`. Turning this feature off results in the operator collecting metrics from the time the KokuMetricsConfig is created, forward.

      ## Limitations and Pre-Requisites
      #### Limitations (Potential for metrics data loss)
      * An integration **must** exist in console.redhat.com for an uploaded payload to be processed by Cost Management. The operator sends the payload to the Red Hat Insights Ingress service which usually returns successfully, but the operator does not currently confirm with Cost Management that the payload was processed. After Ingress accepts the uploaded payload, it is deleted from the operator. If the data within the payload is not processed, a gap will be introduced in the usage metrics. Data may be recollected by deleting the `KokuMetricsConfig`, creating a new `KokuMetricsConfig`, and setting `collect_previous_data: true`. This re-collection of data will gather all data stored in Prometheus, up to 90 days.

      **Note** The following limitations are specific to operators configured to run in a restricted network:
      * The `koku-metrics-operator` will not be able to generate new reports if the PVC storage is full. If this occurs, the reports must be manually deleted from the PVC so that the operator can function as normal.
      * The default report retention is 30 reports (about one week's worth of data). The reports must be manually downloaded and uploaded to console.redhat.com every week, or they will be deleted and the data will be lost.

      #### Storage configuration prerequisite
      The operator will attempt to create and use the following PVC when installed:

            volume_claim_template:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: koku-metrics-operator-data
              spec:
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 10Gi

      If a different PVC should be utilized, a valid PVC should be specified in the KokuMetricsConfig CR as described in the appropriate section below. The PVC to be used may exist already, or the operator will attempt to create it.

      To use the default specification, the follow assumptions must be met:
      1. A default StorageClass is defined.
      2. Dynamic provisioning for that default StorageClass is enabled.

      If these assumptions are not met, the operator will not deploy correctly. In these cases, storage must be manually configured. After configuring storage, a valid PVC template should be supplied in the `volume_claim_template` spec of the KokuMetricsConfig CR.

      ## Configurable parameters:
        * `authentication`:
          * `type: token` -> The authentication method for connecting to `console.redhat.com`. The default and preferred method is `token`. `basic` (deprecated) and `service-account` authentication methods are used when the openshift-config pull-secret does not contain a token for `console.redhat.com`.
          * `secret_name` -> The Secret used by the operator when the authentication type is `basic` (deprecated) or `service-account`. This parameter is required **only if** the authentication type is `basic` (deprecated) or `service-account`.
        * `packaging`:
          * `max_reports_to_store: 30` -> The number of reports to store when configured in air-gapped mode. The default is 30, with a minimum of 1 and no maximum. When the operator is not configured in air-gapped mode, this parameter has no effect. Reports are removed as soon as they are uploaded.
          * `max_size: 100` -> The maximum size for packaged files in Megabytes prior to compression. The default is 100, with a minimum of 1 and maximum of 100.
        * `prometheus_config`:
          * `collect_previous_data: true` -> Toggle for collecting all available data in Prometheus **upon KokuMetricsConfig creation** (This parameter will start to appear in KokuMetricsConfigs that were created prior to v2.0.0 but will not have any effect unless the KokuMetricsConfig is deleted and recreated). The default is `true`. The operator will first look for a `retention` period in the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace and gather data over this time period up to a maximum of 90 days. If this configuration is not set, the default is 14 days. (New in v2.0.0)
          * `disable_metrics_collection_cost_management: false` -> Toggle for disabling the collection of metrics for Cost Management. The default is false. (New in v2.0.0)
          * `disable_metrics_collection_resource_optimization: false` -> Toggle for disabling the collection of metrics for Resource Optimization. The default is false. (New in v2.0.0)
          * `context_timeout: 120` -> The time in seconds before Prometheus queries timeout due to exceeding context timeout. The default is 120, with a minimum of 10 and maximum of 180.
        * `source`:
          * `name: ''` -> The name of the integration the operator will create in `console.redhat.com`. If the name value is empty, the default intergration name is the **cluster id**.
          * `create_source: false` -> Toggle for whether or not the operator will create the integration in `console.redhat.com`. The default is False. This parameter should be switched to True when an integration does not already exist in `console.redhat.com` for this cluster.
          * `check_cycle: 1440` -> The time in minutes to wait between checking if an integration exists for this cluster. The default is 1440 minutes (24 hrs).
        * `upload`:
          * `upload_cycle: 360` -> The time in minutes between payload uploads. The default is 360 (6 hours), minimum is 60 (1 hour).
          * `upload_toggle: true` -> Toggle to turn upload on or off -> true means upload, false means do not upload (false == air-gapped mode). The default is `true`.
          * `upload_wait` -> The amount of time (in seconds) to pause before uploading a payload. The default is a random number between 0 and 35. This is used to decrease service load, but may be set to `0` if desired.
        * `volume_claim_template` -> see the "Storage configuration prerequisite" section above.

      ## Configure the koku-metrics-operator
      **Note** There are separate instructions for configuring the `koku-metrics-operator` to run in a restricted network.
      ##### Configure authentication
      The default authentication for the operator is `token`. No further steps are required to configure token authentication. If `basic` (deprecated) or `service-account` is the preferred authentication method, a Secret which holds the credentials must be created:
      1. On the left navigation pane, select `Workloads` -> `Secrets` -> select Project: `koku-metrics-operator` -> `Create` -> `Key/Value Secret`
      2. Give the Secret a name and add 2 keys (all lowercase) for the respective authentication type. The values for these keys correspond to console.redhat.com credentials:
          * basic auth (deprecated): `username` and `password`
          * service-account auth: `client_id` and `client_secret`

      3. Select `Create`.
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. For `basic` (deprecated) or `service-account` authentication, edit the following values in the spec:
          * Replace `authentication: type:` with `basic` or `service-account`.
          * Add the `secret_name` field under `authentication`, and set it equal to the name of the authentication Secret that was created above. The spec should look similar to the following:

              * for basic auth type (deprecated)
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: basic
              ```

              * for service-account auth type
              ```
                authentication:
                  secret_name: SECRET-NAME
                  type: service-account
              ```

      3. To configure the koku-metrics-operator to create a cost management integration, edit the following values in the `source` field:
          * Replace the `name` field value with the preferred name of the integration to be created.
          * Replace the `create_source` field value with `true`.

          **Note:** if the integration already exists, replace the empty string value of the `name` field with the existing name, and leave `create_source` as false. This will allow the operator to confirm that the integration exists.

      4. If not specified, the operator will create a default PersistentVolumeClaim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec:

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      5. Select `Create`.

      # Restricted Network Usage (disconnected/air-gapped mode)
      ## Installation
      To install the `koku-metrics-operator` in a restricted network, follow the [olm documentation](https://docs.openshift.com/container-platform/latest/operators/admin/olm-restricted-networks.html). The operator is found in the `community-operators` Catalog in the `registry.redhat.io/redhat/community-operator-index:latest` Index. If pruning the index before pushing to the mirrored registry, keep the `koku-metrics-operator` package.

      Within a restricted network, the operator queries prometheus to gather the necessary usage metrics, writes the query results to CSV files, and packages the reports for storage in the PVC. These reports then need to be manually downloaded from the cluster and uploaded to [console.redhat.com](https://console.redhat.com).

      ## Configure the koku-metrics-operator for a restricted network
      ##### Create the KokuMetricsConfig
      Configure the koku-metrics-operator by creating a `KokuMetricsConfig`.
      1. On the left navigation pane, select `Operators` -> `Installed Operators` -> `koku-metrics-operator` -> `KokuMetricsConfig` -> `Create Instance`.
      2. Specify the desired storage. If not specified, the operator will create a default Persistent Volume Claim called `koku-metrics-operator-data` with 10Gi of storage. To configure the koku-metrics-operator to use or create a different PVC, edit the following in the spec:
          * Add the desired configuration to the `volume_claim_template` field in the spec (below is only a template. Any _valid_ `PersistentVolumeClaim` may be defined here):

            ```
              volume_claim_template:
                apiVersion: v1
                kind: PersistentVolumeClaim
                metadata:
                  name: <insert-name>
                spec:
                  storageClassName: <insert-class-name>
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
            ```

          **Note:** If using the YAML View, the `volume_claim_template` field must be added to the spec
      3. (Optional) Specify the desired report retention. The operator will retain 30 reports by default. This corresponds to approximately one week's worth of data if using the default packaging cycle. To modify the number of retained reports:
          * Change the `packaging` spec field `max_reports_to_store` to the desired number of reports to retain. Once this max number is reached, the operator will start removing the oldest packages remaining on the PVC:

            ```
              packaging:
                max_size_MB: 100
                max_reports_to_store: 30
            ```

          **Note:** The number of retained reports directly affects the frequency that reports must be manually downloaded from the PVC. Take caution in setting this to a higher number of reports, as the operator cannot write data to the PVC if the storage is full.
      4. To configure the operator to perform in a restricted network, set the `upload_toggle` to `false`:

        ```
          upload:
            upload_cycle: 360
            upload_toggle: false
        ```

      5. Select `Create`.

      ## Download reports from the Operator & clean up the PVC
      If the `koku-metrics-operator` is configured to run in a restricted network, the metric reports will not automatically upload to cost managment. Instead, they need to be manually copied from the PVC for upload to [console.redhat.com](https://console.redhat.com). The default configuration saves one week of reports which means the process of downloading and uploading reports should be repeated weekly to prevent loss of metrics data. To download the reports, complete the following steps:
      1. Create the following Pod, ensuring the `claimName` matches the PVC containing the report data:

        ```
          kind: Pod
          apiVersion: v1
          metadata:
            name: volume-shell
            namespace: koku-metrics-operator
            labels:
              app: koku-metrics-operator
          spec:
            volumes:
            - name: koku-metrics-operator-reports
              persistentVolumeClaim:
                claimName: koku-metrics-operator-data
            containers:
            - name: volume-shell
              image: busybox
              command: ['sleep', 'infinity']
              volumeMounts:
              - name: koku-metrics-operator-reports
                mountPath: /tmp/koku-metrics-operator-reports
        ```

      2. Use rsync to copy all of the files ready for upload from the PVC to a local folder:

        ```
        $ oc rsync volume-shell:/tmp/koku-metrics-operator-reports/upload local/path/to/save/folder
        ```

      3. Once confirming that the files have been successfully copied, use rsh to connect to the pod and delete the contents of the upload folder so that they are no longer in storage:

        ```
        $ oc rsh volume-shell
        $ rm /tmp/koku-metrics-operator-reports/upload/*
        ```

      4. (Optional) Delete the pod that was used to connect to the PVC:

        ```
        $ oc delete -f volume-shell.yaml
        ```

      ## Create an Integration
      In a restricted network, the `koku-metrics-operator` cannot automatically create an integration. This process must be done manually. In the console.redhat.com platform, open the [Integrations menu](https://console.redhat.com/settings/integrations/) to begin adding an OpenShift integration to Cost Management:

      Prerequisites:
      * The cluster identifier which can be found in the KokuMetricsConfig CR, the cluster Overview page, or the cluster Help > About.

      Creating an integration:
      1. Navigate to the Integrations menu
      2. Select the `Red Hat` tab
      3. Create a new `Red Hat Openshift Container Platform` integration:
          * give the integration a unique name
          * add the Cost Management application
          * add the cluster identifier
      4. In the Source wizard, review the details and click `Finish` to create the source.

      ## Upload the reports to cost managment
      Uploading reports to cost managment is done through curl:

          $ curl -vvvv -F "file=@FILE_NAME.tar.gz;type=application/vnd.redhat.hccm.tar+tgz" https://console.redhat.com/api/ingress/v1/upload -H "Authorization: Bearer ${ACCESS_TOKEN}"

      where `FILE_NAME` is the name of the report to upload. The `ACCESS_TOKEN` is acquired using a service account. See documentation on [creating and managing a service account](https://docs.redhat.com/en/documentation/red_hat_customer_portal/1/html/creating_and_managing_service_accounts).
    displayName: Koku Metrics Operator
    installModes:
    - supported: true
      type: OwnNamespace
    - supported: true
      type: SingleNamespace
    - supported: false
      type: MultiNamespace
    - supported: false
      type: AllNamespaces
    keywords:
    - cost
    - management
    - usage
    - monitor
    labels:
      operatorframework.io/arch.amd64: supported
      operatorframework.io/arch.arm64: supported
      operatorframework.io/arch.ppc64le: supported
      operatorframework.io/arch.s390x: supported
      operatorframework.io/os.linux: supported
    links:
    - name: Koku Metrics Operator source code repository
      url: https://github.com/project-koku/koku-metrics-operator
    maintainers:
    - email: costmanagement@redhat.com
      name: costmanagement
    maturity: alpha
    minKubeVersion: 1.24.0
    provider:
      name: Red Hat
relatedImages:
- image: quay.io/community-operator-pipeline-prod/koku-metrics-operator:4.0.0
  name: ""
- image: quay.io/project-koku/koku-metrics-operator@sha256:6881531e66c4c11c6a8bd60e535040d5c5974848dc6446297c1d9a5feef6f864
  name: koku-metrics-operator
schema: olm.bundle

{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Openshift Community Operators","text":""},{"location":"#about-this-repository","title":"About this repository","text":"<p>This repo is the canonical source for Kubernetes Operators that appear on OpenShift Container Platform and OKD.</p> <p>NOTE The index catalog <code>registry.redhat.io/redhat/community-operator-index:v&lt;OCP Version&gt;</code> is built from this repository and it is consumed by Openshift and OKD to create their sources and built their catalog. To know more about how Openshift catalog are built see the documentation.</p> <p>See our documentation to find out more about Community operators and contribution.</p>"},{"location":"#add-your-operator","title":"Add your Operator","text":"<p>We would love to see your Operator added to this collection. We currently use automated vetting via continuous integration plus manual review to curate a list of high-quality, well-documented Operators. If you are new to Kubernetes Operators start here.</p> <p>If you have an existing Operator read our contribution guidelines on how to package. Then the community operator pipeline will be triggered to test your Operator and merge a Pull Request.</p>"},{"location":"#contributing-guide","title":"Contributing Guide","text":"<ul> <li>Prerequisites</li> <li>Where to place operator</li> <li>Creating pull request (PR)</li> <li>Operator Publishing / Review settings</li> <li>OKD/OpenShift Catalogs criteria and options</li> </ul>"},{"location":"#test-and-release-process-for-the-operator","title":"Test and release process for the Operator","text":"<p>Refer to the Community operator pipeline documentation .</p>"},{"location":"#important-notice","title":"IMPORTANT NOTICE","text":"<p>Some APIs versions are deprecated and are OR will no longer be served on the Kubernetes version <code>1.22/1.25/1.26</code> and consequently on vendors like Openshift <code>4.9/4.12/4.13</code>.</p> <p>What does it mean for you?</p> <p>Operator bundle versions using the removed APIs can not work successfully from the respective releases. Therefore, it is recommended to check if your solutions are failing in these scenarios to stop using these versions OR by setting the <code>\"olm.properties\": '[{\"type\": \"olm.maxOpenShiftVersion\", \"value\": \"&lt;OCP version&gt;\"}]'</code> to block cluster admins upgrades when they have Operator versions installed that can not work well in OCP versions higher than the value informed. Also, by defining a valid OCP range via the annotation <code>com.redhat.openshift.versions</code> into the <code>metadata/annotations.yaml</code> for our solution does not end up shipped on OCP/OKD versions where it cannot be installed.</p> <p>WARNING: <code>olm.maxOpenShiftVersion</code> should ONLY be used if you are 100% sure that your Operator bundle version cannot work in upper releases. Otherwise, you might provide a bad user experience. Be aware that cluster admins will be unable to upgrade their clusters with your solution installed. Then, suppose you do not provide any upper version and a valid upgrade path for those who have your Operator installed be able to upgrade it and consequently be allowed to upgrade their cluster version (i.e from OCP 4.10 to 4.11). In that case, cluster admins might choose to uninstall your Operator and no longer use it so that they can move forward and upgrade their cluster version without it.</p> <p>Please, make sure you check the following announcements: - How to deal with removal of v1beta1 CRD removals in Kubernetes 1.22 / OpenShift 4.9 - Kubernetes API removals on 1.25/1.26 and Openshift 4.12/4.13 might impact your Operator. How to deal with it?</p>"},{"location":"#reporting-bugs","title":"Reporting Bugs","text":"<p>Use the issue tracker in this repository to report bugs.</p>"},{"location":"best-practices/","title":"Operator Best Practices","text":"<p>Check the sections Best Practices for OLM and SDK projects to know more about its best practices and common recommendations, suggestions and conventions, see:</p> <ul> <li>SDK best practices</li> <li>OLM best practices</li> </ul>"},{"location":"community-operator-pipeline/","title":"community-operator-pipeline","text":"<p>The community operator pipeline provides a platform for openshift community contributors to validate, share, and distribute openshift operators.</p> <p>The community operator pipeline is divided into two workflows: 1. The community-hosted-pipeline to test and validate the submitted operator bundle in the PR. 1. The community-release-pipeline to release the operator bundle to the catalog after the PR is merged.</p>"},{"location":"community-operator-pipeline/#community-hosted-pipeline","title":"community-hosted-pipeline","text":"<p>The community hosted pipeline is used to test the submitted Operator bundles.</p> <p>It is intended to be triggered upon the creation of an operator bundle pull request and successfully completes with merging it.</p> <p>As part of the community hosted pipeline, the operator submitted in the PR will be tested in two different ways:</p> <ol> <li>The static tests suite</li> <li>The dynamic tests (Preflight tests)</li> </ol> <p>Note To learn more about preflight tests, please follow this link.</p>"},{"location":"community-operator-pipeline/#static-tests-suite","title":"Static tests suite","text":"<p>As part of the static tests suite, set of a check suite will be run against the submitted bundle and will return warnings and failures (if any) in the operator-sdk bundle validate tool's JSON output format. This results will be posted into the PR.</p> <p>Here is the example how the result will look like in the PR:</p> <p></p>"},{"location":"community-operator-pipeline/#dynamic-tests-preflight-tests","title":"Dynamic tests (Preflight tests)","text":"<p>Note The Preflight tests are the replacement of (orange/kiwi/lemon) test suits.</p> <p>The preflight tests are designed to test and verify the the operator bundle content and the format of the operator bundle. The result link for the logs of the preflight test runs will be posted to the PR as shown below.</p> <p></p> <p>In case of failures, please have a look at the logs of specific tests. If an error is not clear to you, please ask in the PR. Maintainers will be happy to help you with it.</p> <p>Once all of the tests will be passed successfully, the PR will be merged automatically based on the conditions are met by community-hosted-pipeline.</p> <p>The PR will not merge automatically in the following cases: 1. If the brand-new operator is submitted. 1. If the author of the PR is not listed as a reviewer in the <code>ci.yaml</code> file for the respective operator or as a repository maintainer.</p> <p>If there are any of the above cases, the PR needs to be reviewed by the Repositoy maintainers or authorized reviewers. After the approval, the PR needs to be merged manually. Once the PR will be merged, the community-release-pipeline will be triggered automatically.</p> <p>NOTE: The community hosted pipeline run results will be posted in the github PR comment.</p> <p></p>"},{"location":"community-operator-pipeline/#community-release-pipeline","title":"community-release-pipeline","text":"<p>The community release pipeline is responsible for releasing a bundle image which has passed the test validations via community-hosted-pipeline. It's intended to be triggered automatically by the merge of a bundle pull request by the community hosted pipeline. It successfully completes once the bundle has been published to the catalog.</p> <p>NOTE: The community release pipeline run results will be posted in the github PR comment.</p> <p></p>"},{"location":"community-operator-pipeline/#there-are-new-github-pull-request-labels-have-been-introduced-for-the-community-operator-pipeline","title":"There are new github pull request labels have been introduced for the community operator pipeline.","text":"Label Name Label Description community-hosted-pipeline/started This label will be added to the PR when the hosted pipeline will be triggered. community-hosted-pipeline/passed This label will be added to the PR when the hosted pipeline will be passed successfully. community-hosted-pipeline/failed This label will be added to the PR when the hosted pipeline will be failed. community-release-pipeline/started This label will be added to the PR when the release pipeline will be triggered. community-release-pipeline/passed This label will be added to the PR when the release pipeline will be passed successfully. community-release-pipeline/failed This label will be added to the PR when the release pipeline will be failed. validation-failed This label will be added to the PR when the static tests will be failed in hosted pipeline."},{"location":"contributing-prerequisites/","title":"Before submitting your Operator","text":"<p>Important: \"First off, thanks for taking the time to contribute your Operator!\"</p>"},{"location":"contributing-prerequisites/#a-primer-to-openshift-community-operators","title":"A primer to Openshift Community Operators","text":"<p>This project collects Community Operators that work with OpenShift to be displayed in the embedded OperatorHub. If you are new to Operators, start here.</p>"},{"location":"contributing-prerequisites/#sign-your-work","title":"Sign Your Work","text":"<p>The contribution process works off standard git Pull Requests. Every PR needs to be signed. The sign-off is a simple line at the end of the explanation for a commit. Your signature certifies that you wrote the patch or otherwise have the right to contribute the material. The rules are pretty simple if you can certify the below (from developercertificate.org):</p> <pre><code>Developer Certificate of Origin\nVersion 1.1\n\nCopyright (C) 2004, 2006 The Linux Foundation and its contributors.\n1 Letterman Drive\nSuite D4700\nSan Francisco, CA, 94129\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nDeveloper's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n(a) The contribution was created in whole or in part by me and I\n    have the right to submit it under the open source license\n    indicated in the file; or\n\n(b) The contribution is based upon previous work that, to the best\n    of my knowledge, is covered under an appropriate open source\n    license and I have the right under that license to submit that\n    work with modifications, whether created in whole or in part\n    by me, under the same open source license (unless I am\n    permitted to submit under a different license), as indicated\n    in the file; or\n\n(c) The contribution was provided directly to me by some other\n    person who certified (a), (b) or (c) and I have not modified\n    it.\n\n(d) I understand and agree that this project and the contribution\n    are public and that a record of the contribution (including all\n    personal information I submit with it, including my sign-off) is\n    maintained indefinitely and may be redistributed consistent with\n    this project or the open source license(s) involved.\n</code></pre> <p>Then you just add a line to every git commit message:</p> <pre><code>Signed-off-by: John Doe &lt;john.doe@example.com&gt;\n</code></pre> <p>Use your real name (sorry, no pseudonyms or anonymous contributions.)</p> <p>If you set your <code>user.name</code> and <code>user.email</code> git configs, you can sign your commit automatically with <code>git commit -s</code>.</p> <p>Note: If your git config information is set properly then viewing the <code>git log</code> information for your commit will look something like this:</p> <pre><code>Author: John Doe &lt;john.doe@example.com&gt;\nDate:   Mon Oct 21 12:23:17 2019 -0800\n\n    Update README\n\n    Signed-off-by: John Doe &lt;john.doe@example.com&gt;\n</code></pre> <p>Notice the <code>Author</code> and <code>Signed-off-by</code> lines must match.</p>"},{"location":"contributing-via-pr/","title":"Submitting your Operator via Pull Requests (PR) in community operators project","text":""},{"location":"contributing-via-pr/#overview","title":"Overview","text":"<p>To submit an operator one has to do these steps</p> <ol> <li>Fork project <code>https://github.com/redhat-openshift-ecosystem/community-operators-prod</code></li> <li>Make a pull request</li> <li>Place the operator in the target directory. More info<ul> <li>operators</li> </ul> </li> <li>Configure <code>ci.yaml</code> file. More info<ul> <li>Setup reviewers</li> <li>Operator versioning strategy</li> </ul> </li> <li>Verify tests and fix problems, if possible</li> <li>Ask for help in the PR in case of problems</li> </ol>"},{"location":"contributing-via-pr/#pull-request","title":"Pull request","text":"<p>When a pull request is created, a number of tests are executed via community hosted pipeline. One can see the results in the comment section of conversation tab.</p> <p></p>"},{"location":"contributing-via-pr/#you-are-done","title":"You are done","text":"<p>User is done when all tests are green. When the PR is merged, the community release pipeline will be triggered.</p>"},{"location":"contributing-via-pr/#test-results-failed","title":"Test results failed?","text":"<p>When operator tests are failing, one can see a following picture</p> <p></p> <p>In case of failures, please have a look at the logs of specific tests. If an error is not clear to you, please ask in the PR. Maintainers will be happy to help you with it.</p>"},{"location":"contributing-via-pr/#useful-commands-interacting-with-the-pipeline","title":"Useful commands interacting with the pipeline","text":"<p>You can post the following comment/command:</p> Command Functionality <code>/pipeline restart community-hosted-pipeline</code> The hosted pipeline will be re-triggered and PR will be merged if possible. <code>/pipeline restart community-release-pipeline</code> The release pipeline will be re-triggered. <code>/test skip {test_case_name}</code> test_case_name test will be skipped. Please consider that only a subset of tests (currently only pruned graph test) can be skipped."},{"location":"contributing-where-to/","title":"Where to contribute","text":"<p>Once you have forked the upstream repo, you will require to add your Operator Bundle to the forked repo. The forked repo will have directory structure similar to the structure outlined below.</p> <pre><code>\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 operators\n\u2502   \u2514\u2500\u2500 new-operator\n\u2502       \u251c\u2500\u2500 0.0.102\n\u2502       \u2502   \u251c\u2500\u2500 manifests\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 new-operator.clusterserviceversion.yaml\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 new-operator-controller-manager-metrics-service_v1_service.yaml\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 new-operator-manager-config_v1_configmap.yaml\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 new-operator-metrics-reader_rbac.authorization.k8s.io_v1_clusterrole.yaml\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 tools.opdev.io_demoresources.yaml\n\u2502       \u2502   \u251c\u2500\u2500 metadata\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 annotations.yaml\n\u2502       \u2502   \u2514\u2500\u2500 tests\n\u2502       \u2502       \u2514\u2500\u2500 scorecard\n\u2502       \u2502           \u2514\u2500\u2500 config.yaml\n\u2502       \u2514\u2500\u2500 ci.yaml\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Follow the <code>operators</code> directory in the forked repo. Add your Operator Bundle under this <code>operators</code> directory following the example format. 1. Under the <code>operators</code> directory, create a new directory with the name of your operator. 1. Inside of this newly created directory add your <code>ci.yaml</code>. 1. Also, under the new directory create a subdirectory for each version of your Operator. 1. In each version directory there should be a <code>manifests/</code> directory containing your OpenShift yaml files, a <code>metadata/</code> directory containing your <code>annotations.yaml</code> file, and a <code>tests/</code> directory containing the required <code>config.yaml</code> file for the preflight tests.</p> <p>Note To learn more about preflight tests please follow this link.</p> <p>For partners and ISVs, certified operators can now be submitted via connect.redhat.com. If you have submitted your Operator there already, please ensure your submission here uses a different package name (refer to the README for more details).</p>"},{"location":"operator-ci-yaml/","title":"Operator Publishing / Review settings","text":"<p>Each operator might have <code>ci.yaml</code> configuration file to be present in an operator directory (for example <code>operators/aqua/ci.yaml</code>). This configuration file is used by community-operators pipeline to setup various features like <code>reviewers</code> or <code>operator versioning</code>.</p> <p>Note:     One can create or modify <code>ci.yaml</code> file with a new operator version. This operation can be done in the same PR with other operator changes.</p>"},{"location":"operator-ci-yaml/#reviewers","title":"Reviewers","text":"<p>If you want to accelerate publishing your changes, consider adding yourself and others you trust to the <code>reviewers</code> list. If the author of PR will be in that list, changes she/he made will be taken as authorized changes. This will be the indicator for our pipeline that the PR is ready to merge automatically.</p> <p>Note:     If an author of PR is not in <code>reviewers</code> list or not in <code>ci.yaml</code> on <code>main</code> branch, PR will not be merged automatically.</p> <p>Note:     If an author of PR is not in <code>reviewers</code> list and <code>reviewers</code> are present in <code>ci.yaml</code> file. All <code>reviewers</code> will be mentioned in PR comment to check for upcoming changes.</p> <p>For this to work, it is required to setup reviewers in <code>ci.yaml</code> file. It can be done by adding <code>reviewers</code> tag with a list of GitHub usernames. For example</p>"},{"location":"operator-ci-yaml/#example","title":"Example","text":"<pre><code>$ cat &lt;path-to-operator&gt;/ci.yaml\n---\nreviewers:\n  - user1\n  - user2\n\n</code></pre>"},{"location":"operator-ci-yaml/#operator-versioning","title":"Operator versioning","text":"<p>Operators have multiple versions. When a new version is released, OLM can update an operator automatically. There are 2 update strategies possible, which are defined in <code>ci.yaml</code> at the operator top level.</p>"},{"location":"operator-ci-yaml/#replaces-mode","title":"replaces-mode","text":"<p>Every next version defines which version will be replaced using <code>replaces</code> key in the CSV file. It means, that there is a possibility to omit some versions from the update graph. The best practice is to put them in a separate channel then.</p>"},{"location":"operator-ci-yaml/#semver-mode","title":"semver-mode","text":"<p>Every version will be replaced by the next higher version according to semantic versioning.</p>"},{"location":"operator-ci-yaml/#restrictions","title":"Restrictions","text":"<p>A contributor can decide if <code>semver-mode</code> or <code>replaces-mode</code> mode will be used for a specific operator. By default, <code>replaces-mode</code> is activated, when <code>ci.yaml</code> file is present and contains <code>updateGraph: replaces-mode</code>. When a contributor decides to switch and use <code>semver-mode</code>, it will be specified in <code>ci.yaml</code> file or the key <code>updateGraph</code> will be missing.</p>"},{"location":"operator-ci-yaml/#example_1","title":"Example","text":"<pre><code>$ cat &lt;path-to-operator&gt;/ci.yaml\n---\n# Use `replaces-mode` or `semver-mode`.\nupdateGraph: replaces-mode\n</code></pre>"},{"location":"operator-ci-yaml/#kubernetes-max-version-in-csv","title":"Kubernetes max version in CSV","text":"<p>Starting from kubernetes 1.22 some old APIs were deprecated (Deprecated API Migration Guide from v1.22. Users can set <code>operatorhub.io/ui-metadata-max-k8s-version: \"&lt;version&gt;\"</code> in its CSV file to inform its maximum supported Kubernetes version. The following example will inform that operator can handle <code>1.21</code> as maximum Kubernetes version</p> <pre><code>$ cat &lt;path-to-operators&gt;/&lt;name&gt;/&lt;version&gt;/.../my.clusterserviceversion.yaml\nmetadata:\n  annotations:\n    operatorhub.io/ui-metadata-max-k8s-version: \"1.21\"\n</code></pre>"},{"location":"packaging-operator/","title":"Operator structure","text":""},{"location":"packaging-operator/#package-your-operator","title":"Package your Operator","text":"<p>This repository makes use of the Operator Framework and its packaging concept for Operators. Your contribution is welcome in the form of a Pull Request with your Operator packaged for use with Operator Lifecycle Manager.</p>"},{"location":"packaging-operator/#packaging-format","title":"Packaging format","text":"<p>Your Operator submission can be formatted following the <code>bundle</code> or <code>packagemanifest</code> format. The <code>packagemanifest</code> format is a legacy format that is kept for backward compatibility only and then, it strongly recommended to use <code>bundle</code> format. The former allows shipping your entire Operator with all its versions in one single directory. The latter allows shipping individual releases in container images.</p> <p>In general, a released version of your Operator is described in a <code>ClusterServiceVersion</code> manifest alongside the <code>CustomResourceDefinitions</code> of your Operator and additional metadata describing your Operator listing.</p>"},{"location":"packaging-operator/#create-a-clusterserviceversion","title":"Create a ClusterServiceVersion","text":"<p>To add your operator to any of the supported platforms, you will need to submit metadata for your Operator to be used by the Operator Lifecycle Manager (OLM). This is a YAML file called <code>ClusterServiceVersion</code> which contains references to all of the CRDs, RBAC rules, <code>Deployment</code> and container image needed to install and securely run your Operator. It also contains user-visible info like a description of its features and supported Kubernetes versions. Note that your Operator's CRDs are shipped in separate manifests alongside the CSV so OLM can register them during installation (your Operator is not supposed to self-register its CRDs).</p> <p>Follow this guide to create an OLM-compatible CSV for your operator. You can also leverage existing examples in this repository.</p> <p>For more information about the advanced features of the Operator metadata format used here, be sure to check the Operator Lifecycle Manager documentation about how to package webhooks, upgrade readiness probes or an Operator supported on multiple computer architectures (multi-arch).</p>"},{"location":"packaging-operator/#categories","title":"Categories","text":"<p>An Operator's CSV must contain the fields mentioned here for it to be displayed properly within the various platforms. If your operator needs a new category, follow the instructions about categories.</p> <p>There is one CSV per version of your Operator alongside the CRDs.</p>"},{"location":"packaging-operator/#create-a-release","title":"Create a release","text":"<p>The <code>bundle</code> format has a top-level directory named after your Operator name in the <code>ClusterServiceVersion</code> directory. Inside are sub-directories for the individual bundle, named after the semantic versioning release of your Operator.</p> <p>All metadata is defined within the individual release of the Operator. That is, inside each bundle. This includes the channel definitions. The default channel is also defined within the bundle and overwritten by every new bundle you add (this is a known limitation and is being worked on).</p> <p>Within each version, you have your <code>CustomResourceDefinitions</code>, <code>ClusterServiceVersion</code> file (containing the same name and version of your Operator as defined inside the YAML structure) and some metadata about the bundle. You can learn more about the bundle format here and also see an example.</p> <p>Note that this community project only requires you to submit your bundle in the form of metadata. The integrated release pipeline of this repository will take care of publishing your bundle as a container image and maintaining it in a public catalog.</p> <p>Your directory structure might look like this when using the <code>bundle</code> format. Notice that the <code>Dockerfile</code> is optionally and actually ignored. The processing pipeline of this site builds a container image for each of your bundles regardless.</p> <pre><code>$ tree my-operator/\n\nmy-operator/\n\u251c\u2500\u2500 0.1.0\n\u2502   \u251c\u2500\u2500 manifests\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd1.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd2.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd3.crd.yaml\n\u2502   \u2502   \u2514\u2500\u2500 my-operator.v0.1.0.clusterserviceversion.yaml\n\u2502   \u251c\u2500\u2500 metadata\n\u2502   \u2502   \u2514\u2500\u2500 annotations.yaml\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 0.5.0\n\u2502   \u251c\u2500\u2500 manifests\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd1.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd2.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd3.crd.yaml\n\u2502   \u2502   \u2514\u2500\u2500 my-operator.v0.5.0.clusterserviceversion.yaml\n\u2502   \u251c\u2500\u2500 metadata\n\u2502   \u2502   \u2514\u2500\u2500 annotations.yaml\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 1.0.0\n\u2502   \u251c\u2500\u2500 manifests\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd1.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd2.crd.yaml\n\u2502   \u2502   \u251c\u2500\u2500 my-operator-crd3.crd.yaml\n\u2502   \u2502   \u2514\u2500\u2500 my-operator.v1.0.0.clusterserviceversion.yaml\n\u2502   \u251c\u2500\u2500 metadata\n\u2502   \u2502   \u2514\u2500\u2500 annotations.yaml\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 2.0.0\n    \u251c\u2500\u2500 manifests\n    \u2502   \u251c\u2500\u2500 my-operator-crd1.crd.yaml\n    \u2502   \u251c\u2500\u2500 my-operator-crd2.crd.yaml\n    \u2502   \u251c\u2500\u2500 my-operator-crd3.crd.yaml\n    \u2502   \u2514\u2500\u2500 my-operator.v2.0.0.clusterserviceversion.yaml\n    \u251c\u2500\u2500 metadata\n    \u2502   \u2514\u2500\u2500 annotations.yaml\n    \u2514\u2500\u2500 Dockerfile\n...\n</code></pre> <p>If you used <code>operator-sdk</code> to develop your Operator you can also leverage its packaging tooling to create a bundle by just running the target <code>make bundle</code>.</p>"},{"location":"packaging-operator/#moving-from-packagemanifest-to-bundle-format","title":"Moving from <code>packagemanifest</code> to <code>bundle</code> format","text":"<p>Eventually, this repository will only accept bundle format at some point in the future. Also, the <code>bundle</code> format has more features like <code>semver</code> mode or, in the future, installing bundles directly outside of a catalog.</p> <p>Migration of existing content, regardless of whether the Operator was created with the SDK, can be achieved with the <code>opm</code> tool on a per Operator version basis. You can download <code>opm</code> here.</p> <p>Suppose <code>v2.0.0</code> is the version of the Operator you want to test convert to bundle format directory with the <code>opm</code> tool:</p> <pre><code>mkdir /tmp/my-operator-2.0.0-bundle/\ncd /tmp/my-operator-2.0.0-bundle/\nopm alpha bundle build --directory /path/to/my-operator/2.0.0-bundle/ --tag my-operator-bundle:v2.0.0 --output-dir .\n</code></pre> <p>This will have generated the bundle format layout in the current working directory <code>/tmp/my-operator-2.0.0-bundle/</code>:</p> <pre><code>$ tree .\n\n/tmp/my-operator-2.0.0-bundle/\n\u251c\u2500\u2500 manifests\n\u2502   \u251c\u2500\u2500 my-operator-crd1.crd.yaml\n\u2502   \u251c\u2500\u2500 my-operator-crd2.crd.yaml\n\u2502   \u251c\u2500\u2500 my-operator-crd3.crd.yaml\n\u2502   \u2514\u2500\u2500 my-operator.v2.0.0.clusterserviceversion.yaml\n\u251c\u2500\u2500 metadata\n\u2502   \u2514\u2500\u2500 annotations.yaml\n\u2514\u2500\u2500 bundle.Dockerfile\n</code></pre> <p>You can verify the generated bundle metadata for semantic correctness with the <code>operator-sdk</code> on this directory.</p> <pre><code>operator-sdk bundle validate /tmp/my-operator-2.0.0-bundle/ --select-optional name=operatorhub\n</code></pre>"},{"location":"packaging-operator/#about-the-dockerfile","title":"About the Dockerfile","text":"<p>A <code>Dockerfile</code> is typically part of the bundle metadata used to build the bundle image. For security reasons, our release process is generating an internal <code>Dockerfile</code> that is used to build and publish the bundle image. Existing <code>Dockerfile</code> or <code>bundle.Dockerfile</code> will be ignored.  You can leverage the <code>annotations.yaml</code> file to control custom labels the resulting image should have. For example:</p> <pre><code>annotations:\n  # Core bundle annotations.\n  operators.operatorframework.io.bundle.mediatype.v1: registry+v1\n  operators.operatorframework.io.bundle.manifests.v1: manifests/\n  operators.operatorframework.io.bundle.metadata.v1: metadata/\n  operators.operatorframework.io.bundle.package.v1: global-load-balancer-operator\n  operators.operatorframework.io.bundle.channels.v1: alpha\n  operators.operatorframework.io.bundle.channel.default.v1: alpha\n  operators.operatorframework.io.metrics.mediatype.v1: metrics+v1\n  operators.operatorframework.io.metrics.builder: operator-sdk-v1.4.0+git\n  operators.operatorframework.io.metrics.project_layout: go.kubebuilder.io/v3\n\n  # Annotations for testing.\n  operators.operatorframework.io.test.mediatype.v1: scorecard+v1\n  operators.operatorframework.io.test.config.v1: tests/scorecard/\n\n</code></pre> <p>will generate <code>Dockerfile</code></p> <pre><code>FROM scratch\n\n# from metadata/annotations.yaml\nLABEL operators.operatorframework.io.bundle.mediatype.v1=\"registry+v1\"\nLABEL operators.operatorframework.io.bundle.manifests.v1=\"manifests/\"\nLABEL operators.operatorframework.io.bundle.metadata.v1=\"metadata/\"\nLABEL operators.operatorframework.io.bundle.package.v1=\"global-load-balancer-operator\"\nLABEL operators.operatorframework.io.bundle.channels.v1=\"alpha\"\nLABEL operators.operatorframework.io.bundle.channel.default.v1=\"alpha\"\nLABEL operators.operatorframework.io.metrics.mediatype.v1=\"metrics+v1\"\nLABEL operators.operatorframework.io.metrics.builder=\"operator-sdk-v1.4.0+git\"\nLABEL operators.operatorframework.io.metrics.project_layout=\"go.kubebuilder.io/v3\"\nLABEL operators.operatorframework.io.test.mediatype.v1=\"scorecard+v1\"\nLABEL operators.operatorframework.io.test.config.v1=\"tests/scorecard/\"\n\nCOPY ./manifests manifests/\nCOPY ./metadata metadata/\nCOPY ./tests/scorecard/ tests/scorecard/\n</code></pre> <p>!!! note     If you specify the <code>operators.operatorframework.io.test.config.v1</code> to embed scorecard tests in your bundle, make sure the supplied directory path (e.g. <code>tests/scorecard/</code> relative from the bundle root directory) exists, otherwise, the validation will fail.</p> <p>You can download <code>operator-sdk</code> here.</p>"},{"location":"packaging-operator/#operator-icon","title":"Operator icon","text":"<p>The icon is defined in a CSV as <code>spec.icon</code>. If you don't have an own icon, you should use a default one:</p> <pre><code>  icon:\n    - base64data: \"PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNTguNTEgMjU4LjUxIj48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2QxZDFkMTt9LmNscy0ye2ZpbGw6IzhkOGQ4Zjt9PC9zdHlsZT48L2RlZnM+PHRpdGxlPkFzc2V0IDQ8L3RpdGxlPjxnIGlkPSJMYXllcl8yIiBkYXRhLW5hbWU9IkxheWVyIDIiPjxnIGlkPSJMYXllcl8xLTIiIGRhdGEtbmFtZT0iTGF5ZXIgMSI+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMTI5LjI1LDIwQTEwOS4xLDEwOS4xLDAsMCwxLDIwNi40LDIwNi40LDEwOS4xLDEwOS4xLDAsMSwxLDUyLjExLDUyLjExLDEwOC40NSwxMDguNDUsMCwwLDEsMTI5LjI1LDIwbTAtMjBoMEM1OC4xNiwwLDAsNTguMTYsMCwxMjkuMjVIMGMwLDcxLjA5LDU4LjE2LDEyOS4yNiwxMjkuMjUsMTI5LjI2aDBjNzEuMDksMCwxMjkuMjYtNTguMTcsMTI5LjI2LTEyOS4yNmgwQzI1OC41MSw1OC4xNiwyMDAuMzQsMCwxMjkuMjUsMFoiLz48cGF0aCBjbGFzcz0iY2xzLTIiIGQ9Ik0xNzcuNTQsMTAzLjQxSDE0MS42NkwxNTQuOSw2NS43NmMxLjI1LTQuNC0yLjMzLTguNzYtNy4yMS04Ljc2SDEwMi45M2E3LjMyLDcuMzIsMCwwLDAtNy40LDZsLTEwLDY5LjYxYy0uNTksNC4xNywyLjg5LDcuODksNy40LDcuODloMzYuOUwxMTUuNTUsMTk3Yy0xLjEyLDQuNDEsMi40OCw4LjU1LDcuMjQsOC41NWE3LjU4LDcuNTgsMCwwLDAsNi40Ny0zLjQ4TDE4NCwxMTMuODVDMTg2Ljg2LDEwOS4yNCwxODMuMjksMTAzLjQxLDE3Ny41NCwxMDMuNDFaIi8+PC9nPjwvZz48L3N2Zz4=\"\n      mediatype: \"image/svg+xml\"\n</code></pre> <p>Supported formats: svg, jpg, png</p>"},{"location":"packaging-operator/#updating-your-existing-operator","title":"Updating your existing Operator","text":"<p>Unless of a purely cosmetic nature, subsequent updates to your Operator should result in new <code>bundle</code> directories being added, containing an updated CSV as well as copied, updated and/or potentially newly added CRDs. Within your new CSV, update the <code>spec.version</code> field to the desired new semantic version of your Operator.</p> <p>In order to have OLM enable updates to your a new Operator version you can choose between three update modes: <code>semver-mode</code>, <code>semver-skippatch-mode</code> and <code>replaces-mode</code>. The default is <code>semver-mode</code>. If you want to change the default, place a file called <code>ci.yaml</code> in your top-level directory (works for both <code>packagemanifest</code> or <code>bundle</code> format) and set it to either of the two other values. For example:</p> <pre><code>updateGraph: replaces-mode\n</code></pre>"},{"location":"packaging-operator/#semver-mode","title":"semver-mode","text":"<p>OLM treats all your Operator versions with semantic version rules and updates them in order of those versions. That is, every version will be replaced by the next higher version according to a semantic versioning sort order. During an update on the cluster, OLM will update to the latest version, one version at a time. To use this, simply specify <code>spec.version</code> in your CSV. If you accidentally add <code>spec.replaces</code> this will contradict semantic versioning and raise an error.</p>"},{"location":"packaging-operator/#replaces-mode","title":"replaces-mode","text":"<p>Each Operator bundle not only contains <code>spec.version</code> but also points to an older version it can upgrade from via <code>spec.replaces</code> key in the CSV file, e.g. <code>replaces: my-operator.v1.0.0</code>. From this chain of back pointers, OLM computes the update graph at runtime. This allows us to omit some versions from the update graph or release special leaf versions.</p> <p>Regardless of which mode you choose to have OLM create update paths for your Operator, it continuously update your Operator often as new features are added and bugs are fixed.</p>"},{"location":"packaging-operator/#channels","title":"Channels","text":"<p>Use channels to allow your users to select a different update cadence, e.g. <code>stable</code> vs. <code>nightly</code>. If you have only a single channel the use of <code>defaultChannel</code> is optional.</p> <p>An example of <code>my-operator.package.yaml</code>:</p> <pre><code>packageName: my-operator\nchannels:\n- name: stable\n  currentCSV: my-operator.v1.0.0\n- name: nightly\n  currentCSV: my-operator.v1.0.3-beta\ndefaultChannel: stable\n</code></pre> <p>Your CSV versioning should follow semantic versioning concepts. Again, <code>packageName</code> is the suffix of the <code>package.yaml</code> file name and the field in <code>spec.name</code> in the CSV should all refer to the same Operator name.</p>"},{"location":"packaging-operator/#operator-bundle-editor","title":"Operator Bundle Editor","text":"<p>You can now create your Operator bundle using the bundle editor. Starting by uploading your Kubernetes YAML manifests, the forms on the page will be populated with all valid information and used to create the new Operator bundle. You can modify or add properties through these forms as well. The result will be a downloadable ZIP file.</p>"},{"location":"packaging-operator/#provide-information-about-your-operator","title":"Provide information about your Operator","text":"<p>A large part of the information gathered in the CSV is used for user-friendly visualization on OperatorHub.io or components like the embedded OperatorHub in OpenShift. Your work is on display, so please ensure to provide relevant information in your Operator's description, specifically covering:</p> <ul> <li>What the managed application is about and where to find more information</li> <li>The features of your Operator and how to use it</li> <li>Any manual steps required to fulfill pre-requisites for running/installing your Operator</li> </ul>"},{"location":"packaging-required-criteria-ocp/","title":"OKD/OpenShift Catalogs criteria and options","text":""},{"location":"packaging-required-criteria-ocp/#okdopenshift-catalogs-criteria-and-options","title":"OKD/OpenShift Catalogs criteria and options","text":""},{"location":"packaging-required-criteria-ocp/#overview","title":"Overview","text":"<p>To distribute on OpenShift Catalogs, you will need to comply with the same standard criteria defined for <code>OperatorHub.io</code> (see Common recommendations and suggestions). Then, additionally, you have some requirements and options which follow.</p> <p>IMPORTANT Kubernetes has been deprecating API(s) which will be removed and no longer available in <code>1.22</code> and in the Openshift version <code>4.9</code>. Note that your project will be unable to use them on <code>OCP 4.9/K8s 1.22</code> and then, it is strongly recommended to check Deprecated API Migration Guide from v1.22 and ensure that your projects have them migrated and are not using any deprecated API.</p> <p>Note that your operator using them will not work in  <code>1.22</code> and in the Openshift version <code>4.9</code>. OpenShift 4.8 introduces two new alerts that fire when an API that will be removed in the next release is in use. Check the event alerts of your Operators running on 4.8 and ensure that you will not find any warning about these API(s) still being used by it.</p> <p>Also, to prevent workflow issues, its users will need to have installed in their OCP cluster a version of your operator compatible with 4.9 before they try to upgrade their cluster from any previous version to 4.9 or higher. In this way, it is recommended to ensure that your operators are no longer using these API(s) versions. However, If you still need to publish the operator bundles with any of these API(s) for use on earlier k8s/OCP versions, ensure that the operator bundle is configured accordingly.</p> <p>Taking the actions below will help prevent users from installing versions of your operator on an incompatible version of OCP, and also prevent them from upgrading to a newer version of OCP that would be incompatible with the version of your operator that is currently installed on their cluster.</p>"},{"location":"packaging-required-criteria-ocp/#configure-the-max-openshift-version-compatible","title":"Configure the max OpenShift Version compatible","text":"<p>Use the <code>olm.openShiftMaxVersion</code> annotation in the CSV to prevent the user from upgrading their OCP cluster before upgrading the installed operator version to any distribution which is compatible with:</p> <pre><code>apiVersion: operators.coreos.com/v1alpha1\nkind: ClusterServiceVersion\nmetadata:\n  annotations:\n    # Prevent cluster upgrades to OpenShift Version 4.9 when this\n    # bundle is installed on the cluster\n    \"olm.properties\": '[{\"type\": \"olm.maxOpenShiftVersion\", \"value\": \"4.8\"}]'\n</code></pre> <p>The CSV annotation will eventually prevent the user from upgrading their OCP cluster before they have installed a version of your operator which is compatible with <code>4.9</code>. However, note that it is important to make these changes now as users running workloads with deprecated API(s) that are looking to upgrade to OCP 4.9 will need to be running operators that have this annotation set in order to prevent the cluster upgrade and potentially adversely impacting their crucial workloads.</p> <p>This option is useful when you know that the current version of your project will not work well on some specific Openshift version.</p>"},{"location":"packaging-required-criteria-ocp/#configure-the-openshift-distribution","title":"Configure the Openshift distribution","text":"<p>Use the annotation <code>com.redhat.openshift.versions</code> in <code>bundle/metadata/annotations.yaml</code> to ensure that the index image will be generated with its OCP Label, to prevent the bundle from being distributed on to 4.9:</p> <pre><code>com.redhat.openshift.versions: \"v4.6-v4.8\"\n</code></pre> <p>This option is also useful when you know that the current version of your project will not work well on some specific OpenShift version. By using it you defined the Openshift versions where the Operator should be distributed and the Operator will not appear in a catalog of an Openshift version that is outside of the range. You must use it if you are distributing a solution that contains deprecated API(s) and will no longer be available in later versions. For more information see Managing OpenShift Versions.</p>"},{"location":"packaging-required-criteria-ocp/#validate-the-bundle-with-the-common-criteria-to-distribute-via-olm-with-sdk","title":"Validate the bundle with the common criteria to distribute via OLM with SDK","text":"<p>Also, you can check the bundle via <code>operator-sdk bundle validate</code> against the suite  Validator Community Operators and the K8s Version that you are intended to publish:</p> <pre><code>operator-sdk bundle validate ./bundle --select-optional suite=operatorframework --optional-values=k8s-version=1.22\n</code></pre> <p>NOTE: The validators only check the manifests which are shipped in the bundle. They are unable to ensure that the project's code does not use the Deprecated/Removed API(s) in 1.22 and/or that it does not have as dependency another operator that uses them.</p>"},{"location":"packaging-required-criteria-ocp/#validate-the-bundle-with-the-specific-criteria-to-distribute-in-openshift-catalogs","title":"Validate the bundle with the specific criteria to distribute in Openshift catalogs","text":"<p>Pre-requirement Download the binary. You might want to keep it in your <code>$GOPTH/bin</code></p> <p>Then, we can use the experimental OpenShift OLM Catalog Validator to check your Operator bundle. In this case, we need to inform the bundle and the annotations.yaml file paths:</p> <pre><code>$ ocp-olm-catalog-validator my-bundle-path/bundle  --optional-values=\"file=bundle-path/bundle/metadata/annotations.yaml\"\n</code></pre> <p>Following is an example of an Operator bundle that uses the removed APIs in 1.22 and is not configured accordingly:</p> <pre><code>$ ocp-olm-catalog-validator bundle/ --optional-values=\"file=bundle/metadata/annotations.yaml\"\nWARN[0000] Warning: Value memcached-operator.v0.0.1: this bundle is using APIs which were deprecated and removed in v1.22. More info: https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22. Migrate the API(s) for CRD: ([\"memcacheds.cache.example.com\"])\nERRO[0000] Error: Value : (memcached-operator.v0.0.1) olm.maxOpenShiftVersion csv.Annotations not specified with an OCP version lower than 4.9. This annotation is required to prevent the user from upgrading their OCP cluster before they have installed a version of their operator which is compatible with 4.9. For further information see https://docs.openshift.com/container-platform/4.8/operators/operator_sdk/osdk-working-bundle-images.html#osdk-control-compat_osdk-working-bundle-images\nERRO[0000] Error: Value : (memcached-operator.v0.0.1) this bundle is using APIs which were deprecated and removed in v1.22. More info: https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22. Migrate the APIs for this bundle is using APIs which were deprecated and removed in v1.22. More info: https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-22. Migrate the API(s) for CRD: ([\"memcacheds.cache.example.com\"]) or provide compatible version(s) via the labels. (e.g. LABEL com.redhat.openshift.versions='4.6-4.8')\n</code></pre>"},{"location":"packaging-required-fields/","title":"Required fields within your CSV","text":""},{"location":"packaging-required-fields/#preparing-your-csv-for-use-with-olm","title":"Preparing your CSV for use with OLM","text":"<p>Before you begin, we strongly advise that you follow Operator-Lifecycle-Manager's docs on building a CSV for the Operator Framework. These outline the functional purpose of the CSV and which fields are required for installing your Operator CSV through OLM.</p> <p>Note that if you used <code>operator-sdk</code> to develop your Operator you can also leverage its packaging tooling to create a bundle by just running the target <code>make bundle</code>.</p>"},{"location":"packaging-required-fields/#required-fields-for-operatorhub","title":"Required fields for OperatorHub","text":"<p>An Operator's CSV must contain the following fields and annotations for it to be displayed properly within OperatorHub.io and OperatorHub in OCP. Below is a guideline explaining each field, and at the bottom of this document is a full example of such a CSV.</p> <pre><code>metadata:\n  annotations:\n    capabilities: One of the following: Basic Install, Seamless Upgrades, Full Lifecycle, Deep Insights, Auto Pilot. For more information see https://www.operatorhub.io/images/capability-level-diagram.svg\n    categories: A comma separated list of categories from the values below. If not set, this will be set to \"Other\" in the UI\n    containerImage: The repository that hosts the operator image. The format should match ${REGISTRYHOST}/${USERNAME}/${NAME}:${TAG}\n    createdAt: The date that the operator was created. The format should match yyyy-mm-ddThh:mm:ssZ\n    support: The name of the individual, company, or service that maintains this operator\n    repository: (Optional) a URL to a source code repository of the Operator, intended for community Operators to direct users where to file issues / bug\n    alm-examples: A string of a JSON list of example CRs for the operator's CRDs\n    description: |-\n      A short description of the operator that will be displayed on the marketplace tile\n      If this annotation is not present, the `spec.description` value will be shown instead\n      In either case, only the first 135 characters will appear\nspec:\n  displayName: A short, readable name for the operator\n  description: A detailed description of the operator, preferably in markdown format\n  icon:\n  - base64data: A base 64 representation of an image or logo associated with your operator\n    mediatype: One of the following: image/png, image/jpeg, image/gif, image/svg+xml\n  version: The operator version in semver format\n  maintainers:\n  - name: The name of the individual, company, or service that maintains this operator\n    email: Email to reach maintainer\n  provider:\n    name: The name of the individual, company, or service that provides this operator\n  links:\n  - name: Title of the link (ex: Blog, Source Code etc.)\n    url: url/link\n  keywords:\n  - 'A list of words that relate to your operator'\n  - 'These are used when searching for operators in the UI'\n</code></pre>"},{"location":"packaging-required-fields/#logo-requirements","title":"Logo requirements","text":"<p>The logo for your Operator is inlined into the CSV as a base64-encoded string. The height:width ratio should be 1:2. The maximum dimensions are 80px for width and 40px in height.</p>"},{"location":"packaging-required-fields/#categories","title":"Categories","text":"<p>For the best user experience, choose from the categories.</p> <p>If none of these categories fit your operator, please open a separate PR against categories.json. Once merged, you can open a PR with your operator assigned to your new category.</p>"},{"location":"packaging-required-fields/#example-csv","title":"Example CSV","text":"<p>Below is an example of what the <code>descheduler</code> CSV may look like if it contained the expected annotations:</p> <pre><code>apiVersion: operators.coreos.com/v1alpha1\nkind: ClusterServiceVersion\nmetadata:\n  annotations:\n    capabilities: Seamless Upgrades\n    categories: \"OpenShift Optional\"\n    containerImage: registry.svc.ci.openshift.org/openshift/origin-v4.0:descheduler-operator\n    createdAt: 2019-01-01T11:59:59Z\n    description: An operator to run the OpenShift descheduler\n    repository: https://github.com/openshift/descheduler-operator\n    alm-examples: |\n      [\n        {\n          \"apiVersion\": \"descheduler.io/v1alpha1\",\n          \"kind\": \"Descheduler\",\n          \"metadata\": {\n            \"name\": \"example-descheduler-1\"\n          },\n          \"spec\": {\n            \"schedule\": \"*/1 * * * ?\",\n            \"strategies\": [\n              {\n                \"name\": \"lownodeutilization\",\n                \"params\": [\n                  {\n                    \"name\": \"cputhreshold\",\n                    \"value\": \"10\"\n                  },\n                  {\n                    \"name\": \"memorythreshold\",\n                    \"value\": \"20\"\n                  },\n                  {\n                    \"name\": \"memorytargetthreshold\",\n                    \"value\": \"30\"\n                  }\n                ]\n              }\n            ]\n          }\n        }\n      ]\n...\n...\n...\nspec:\n  displayName: Descheduler\n  description: |-\n    # Descheduler for Kubernetes\n\n    ## Introduction\n\n    Scheduling in Kubernetes is the process of binding pending pods to nodes, and is performed by\n    a component of Kubernetes called kube-scheduler. The scheduler's decisions, whether or where a\n    pod can or can not be scheduled, are guided by its configurable policy which comprises of set of\n    rules, called predicates and priorities. The scheduler's decisions are influenced by its view of\n    a Kubernetes cluster at that point of time when a new pod appears first time for scheduling.\n    As Kubernetes clusters are very dynamic and their state change over time, there may be desired\n    to move already running pods to some other nodes for various reasons\n\n    * Some nodes are under or over utilized.\n    * The original scheduling decision does not hold true any more, as taints or labels are added to\n    or removed from nodes, pod/node affinity requirements are not satisfied any more.\n    * Some nodes failed and their pods moved to other nodes.\n      New nodes are added to clusters.\n\n    Consequently, there might be several pods scheduled on less desired nodes in a cluster.\n    Descheduler, based on its policy, finds pods that can be moved and evicts them. Please\n    note, in current implementation, descheduler does not schedule replacement of evicted pods\n    but relies on the default scheduler for that.\n\n    ## Note\n\n    Any api could be changed any time without any notice. That said, your feedback is\n    very important and appreciated to make this project more stable and useful.\n  icon:\n  - base64data: this+is+a+base64-string==\n    mediatype: image/png\n  version: 0.0.1\n  provider:\n    name: Red Hat, Inc.\n  maintainers:\n  - email: support@redhat.com\n    name: Red Hat\n  links:\n  - name: GitHub Repository\n    url: https://github.com/openshift/descheduler-operator\n  keywords: ['deschedule', 'scale', 'binpack', 'efficiency']\n ...\n ...\n ...\n</code></pre>"},{"location":"pull_request_template/","title":"Pull request template","text":"<p>Thanks for submitting your Operator. Please check the below list before you create your Pull Request.</p>"},{"location":"pull_request_template/#new-submissions","title":"New Submissions","text":"<ul> <li>[ ] Are you familiar with our contribution guidelines?</li> <li>[ ] Are you familiar with our operator pipeline?</li> <li>[ ] Have you tested your Operator with all Custom Resource Definitions packaging?</li> <li>[ ] Have you tested your Operator in all supported installation modes?</li> <li>[ ] Have you considered whether you want to use semantic versioning order?</li> <li>[ ] Is your submission signed?</li> <li>[ ] Is operator icon set?</li> </ul>"},{"location":"pull_request_template/#your-submission-should-not","title":"Your submission should not","text":"<ul> <li>[ ] Add more than one operator bundle per PR</li> <li>[ ] Modify any operator</li> <li>[ ] Rename an operator</li> <li>[ ] Modify any files outside the above mentioned folders</li> <li>[ ] Contain more than one commit. Please squash your commits.</li> </ul>"},{"location":"pull_request_template/#operator-description-must-contain-in-order","title":"Operator Description must contain (in order)","text":"<ol> <li>[ ] Description of the managed Application and where to find more information</li> <li>[ ] Features and capabilities of your Operator and how to use it</li> <li>[ ] Any manual steps about potential pre-requisites for using your Operator</li> </ol>"},{"location":"pull_request_template/#operator-metadata-should-contain","title":"Operator Metadata should contain","text":"<ul> <li>[ ] Human readable name and 1-liner description about your Operator</li> <li>[ ] Valid category name<sup>1</sup></li> <li>[ ] One of the pre-defined capability levels<sup>2</sup></li> <li>[ ] Links to the maintainer, source code and documentation</li> <li>[ ] Example templates for all Custom Resource Definitions intended to be used</li> <li>[ ] A quadratic logo</li> </ul> <p>Remember that you can preview your CSV here.</p> <p>--</p> <p><sup>1</sup> If you feel your Operator does not fit any of the pre-defined categories, file an issue against this repo and explain your need</p> <p><sup>2</sup> For more information see here</p>"}]}